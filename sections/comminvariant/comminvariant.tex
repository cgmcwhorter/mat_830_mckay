% !TEX root = ../../mat830_mckay.tex
\newpage
\section{Commutative Algebra of Invariant Rings}
\subsection{Noether's Theorem}

There are two standard approaches to this topic: a graded ring approach and a local ring approach. We shall take the former. Let $k$ be a field and $W$ a $d$-dimensional $k$-vector space. Furthermore, let $G \subseteq \GL_n(W) \cong \GL_n(k)$ be a finite group with $|G| \in k^\times$. Define $S=k[W] \cong k[x_1,\ldots,x_d]$ and let $R= S^G$ be its invariant ring. In particular, $R \subseteq S$ is a subalgebra. Now invariant rings are `nicer' than a typical randomly chosen subring of a polynomial ring, by which we mean that there is a `nice' operator on the invariant subring, namely the Reynold's operator $\rho: S \to R$ given by
		\[
		\rho(s)= \dfrac{1}{|G|} \sum_{g \in S} g_S.
		\]
The Reynold's operator is an $R$-linear split surjection, so $S \cong R \oplus \ker \rho$ as $R$-modules. Furthermore, when working with the ring of invariants, one works with symmetric polynomials, which are inherently `nicer' than typical functions. The goal of this section will be to prove the following theorem of Noether:


% \noether28
\begin{restatable}[Noether, 1928]{thm}{noether28} \label{thm:noether28}
The ring $R$ is a noetherian integrally closed domain of Krull dimension $d= \dim_k W$. 
\end{restatable}


\begin{rem}
None of these properties of Noether's Theorem hold for arbitrary subrings of polynomial rings. 
\end{rem}


Recall that the Krull dimension of a $k$-algebra $A$ is the maximal number of algebraically independent elements over $k$. This definition is equivalent to the transcendence degree of the quotient field $Q(A)$ over $k$. If $A$ is the $\C$-algebra given by the coordinate ring of a collection of polynomials, xthen the Krull dimension is the topological dimension of the vanishing set corresponding to $A$; that is, if $A= k[y_1,\ldots,y_m]/(f_1,\ldots,f_r)$, then $\dim A= \dim V(f_1,\ldots,f_r) \subseteq \C^m$. We first show that a polynomial ring is an integral extension of its invariants ring.
 
 
 \begin{lem}
 Let $S=[k_1,\ldots,x_d]$ and $R=S^G$ its ring of invariants. The extension $R \hookrightarrow S$ is integral, i.e. every element of $S$ is a root of a monic polynomial with coefficients in $R$. 
 \end{lem}

\pf For $s \in S$, define $f_s(t):= \prod_{g \in G} (t-gs)$. Then $f_s(t)$ is monic in $t$ and has $s$ as a root since $t-s$ is a factor of $f_s(t)$. The action of $G$ permutes the factors of $f_s(t)$, so it fixes the coefficients of $f_s(t)$. Therefore, $f_s(t) \in R[x]$. \qed \\


This already shows that $\dim R= \dim S= d$ since integral extensions satisfy Going-Up and Going-Down, and thus preserve dimension. We know also that if $A \hookrightarrow B$ is an integral extension of rings and $B$ is finitely generated as an $A$-algebra, then $B$ is finitely generated as an $A$-module (see Atiyah-MacDonald~\cite[Ch.~5]{atiyahmac}). It then follows that


\begin{cor}
Let $S=[k_1,\ldots,x_d]$ and $R=S^G$ its ring of invariants. Then $S$ is a finitely generated $R$-module of rank $|G|$.
\end{cor}

\pf It is enough to show that $S$ is a finitely generated $R$-algebra. Now $S$ is generated over $k$ by $x_1,\ldots,x_d$, so that it is generated over $R$ by $x_1, \ldots, x_d$ as well so that $S$ is a finitely generated $R$-module. It remains to show that $S$ has rank $|G|$. Recall that the rank of a module $M$ over a domain $A$ is $\dim_{Q(A)} M \otimes_A Q(A)$. So we need to compute $\dim_{Q(R)}(S \otimes_R Q(R))$.  But $S \otimes_R Q(R)$ is just $Q(S)$ by integrality. Then any $s \in S$ satisfies an equation $s^p + r_1s^{p-1}+\cdots+r_{p-1}s+r_p=0$, where $r_i \in R$ and $r_p \neq 0$. Then $s(s^{p-1}+r_1s^{p-2}+\cdots+r_{p-1})= -r_p$. Then
	\[
	\dfrac{1}{s}= -\dfrac{1}{r_p} \left( r_1 s^{p-2} + \cdots + r_{p-1} \right).
	\]
If you invert everything in $R$, then you have effectively inverted everything in $s$ by the above. So we need $\dim_{Q(R)} Q(S)$. This a Galois field extension, $Q(S)^G= Q(R)$ so it has degree $|G|$. \qed \\


We now prove that $R$ is noetherian: \\

We know that $S$ is integral over $R$, so that each $x_i$ is integral over $R$. Let $f_1(t), \ldots, f_d(t)$ be monic polynomials with $f_i(x_i)=0$. Let $B \subseteq R$ be the $k$-subalgebra generated by all the coefficients of $f_1,\ldots,f_d$. Then $B$ is finitely generated as a $k$-algebra so that it is noetherian by the Hilbert Basis Theorem. $S$ is integral over $B$, and finitely generated as a $B$-algebra, so finitely generated as a $B$-module. Now $B$ is noetherian and $S$ is a finitely generated $B$-module, every $B$-submodule of $S$ is a finitely generated module. In particular, $R$ must be a finitely generated $B$-module and hence is a noetherian module. Ideals in $R$ are $B$-submodules of $R$ and hence satisfy the ascending chain condition. Hence, $R$ is noetherian. \qed \\



We now prove that $R$ is integrally closed in its quotient field (normal): \\


We know that $Q(S)^= Q(R)$. 


% Field diagram
% 		     Q(S)
%                /        \
% 		S	     \
% 		  \          Q(R)
% 	                R/		


If $x=a/b \in Q(R)$ is integral over $R$, then in particular $x \in Q(S)$ and is integral over $S$. Polynomial rings are integrally closed in their quotient field. So $x \in S$. Hence, $x \in S \cap Q(R)= S \cap Q(S)^G= S^G= R$. When is $R$ a UFD? Always? Never? In between? We know that $S \cong k[x_1,\ldots,x_d]$ is a UFD but $k[u,v]^{C_2}= k[u^2,uv,v^2] \cong k[a,b,c]/(ac-b^2)$ is not a UFD since $u^2 \cdot v^2= (uv)^2$. If we assume that $G$ has no nontrivial linear characters, i.e. no group homomorphisms $G \to k^\times$, then the invariant ring is a UFD. 

\pf Let $r \in R$, then $r \in S$, so we can factor $r= q_1^{a_1} \cdots q_m^{a_n}$, where each $q_i$ is irreducible in $S$ are pairwise non-associate. The $q_i$'s are not necessarily permuted by $G$, but the ideals $(q_1),\ldots,(q_m) \subseteq S$ are. Let $O_1,\ldots,O_e$ be the orbits of the ideals $(q_1),\ldots,(q_m)$ under this action and set
	\[
	Q_j = \prod_{(q_i) \in O_j} q_i^{a_i}
	\]
for $j=1,\ldots,e$. The ideal $(Q_j)$ is stable under the action of $G$, so in particular for any $g \in G$, $gQ_j \in (Q_j)$ so $gQ_j$ is a multiple of $Q_j$. For degree reasons, $gQ_j= \lambda_g Q_j$ for some $\lambda_g \in k^\times$. The function $\lambda: G \to k^\times$ given by $g \mapsto \lambda_g$ (we get one such function for each orbit) and it is a group homomorphism. By assumption, $\lambda$ must be trivial, i.e. $gQ_j= Q_j$ for every $g \in G$ and $j=1,\ldots,e$. Then $Q_j \in R$ for every $j$ and $r= Q_1Q_2 \cdots Q_e$ is a factorization in $R$. Each $Q_j$ is irreducible because it is a product over a single orbit. It is routine, although tedious, to check uniqueness. \qed \\


\begin{ex}
$R= S^G$ is a UFD in the following cases (this is not a complete list, just examples): if $G$ is a nonabelian simple group, e.g. $A_n$ for $n \geq 5$ note that $A_5$ is the $\cI \cong A_5$ group, then we see that the $E_8$ singularity defined by $x^2+y^3+z^5=0$ is a UFD. Or $G= [G,G]$, i.e. every element is a commutator or a product of commutators (in $k^\times$ they are forced to be abelian so go to 1), such groups are called perfect. OR $k= \Q$ and $G$ has odd order (so then does every element) and every image of every element must then be of odd order, which there are none. One can generalize this to $|k|= p^e$ and $\gcd(|G|,|k^\times|=q-1)$. 
\end{ex}


Having proved Noether's Theorem, our next goal is the Hochster-Eagon Theorem that $R= S^G$, i.e. invariant rings are Cohen-Macaulay. We work with graded rings (recall that $k[x_1,\ldots,x_n]= \bigoplus_p k[x_1,\ldots,x_n]_p$), the $p$th graded piece consisting of homogeneous polynomials of degree $p$ and our group actions preserve degree so $k[x_1,\ldots,x_n]^= \bigoplus_p k[x_1,\ldots,x_n]_p^G$. Let $A= \bigoplus_{i=1}^\infty A_i= A_0 \oplus A_1 \oplus \cdots$ be a graded ring with $A_0= k$ a field. Sometimes [Bruns-Herzog] such rings are called *local since they have a unique homogeneous maximal ideal $\fm= A_1 \oplus A_2 \oplus \cdots$. 


\begin{dfn}[Homogenous System of Parameters]
A homogeneous system of parameters for $A$ is a sequence of elements $a_1,\ldots,a_t$ such that $A$ is a finitely generated module over the (graded subring) $k[a_1,\ldots,a_t]$. 
\end{dfn}







%%%%

\subsection{Cohen-Macaulay Rings \& Modules}

\begin{dfn}[Homogeneous]
Let $A= \bigoplus_{i=0}^\infty A_i$ be an $\N$-graded ring with $A_0=k$ a field. An element $a \in A$ is homogeneous if it lies in a unique $A_i$.
\end{dfn}


\begin{dfn}[Homogeneous System of Parameters]
Let $A= \bigoplus_{i=0}^\infty A_i$ be an $\N$-graded ring with $A_0=k$ a field. A sequence $a_1,\ldots,a_m$ of homogeneous elements is called a homogeneous system of parameters (hsop) if $m = \dim A$ and $A$ is a finitely generated module over the graded subring $k[a_1,\ldots,a_n]$. Equivalently, $A/(a_1,\ldots,a_m)$, where $k= \dim A$, is a finite dimensional $k$-vector space. 
\end{dfn}


\begin{ex} \hfill
\begin{enumerate}[(i)]
\item Consider the polynomial ring $A= k[x^2,xy,y^2]$. We claim $\{x^2,y^2\}$ is a hsop. Consider $B= k[x^2,y^2] \subseteq A$. As a $B$-module, $A$ is generated by $1$ and $xy$. Equivalently, $A \cong k[a,b,c]/(ac-b^2)$, $\{a,c\}$ is a hsop as $A/(a,c) \cong k[a,b,c]/(ac-b^2,a,c) \cong k[b]/(b^2)$. 

\item Consider the ring $A= k[x^2,x^3,y,xy]$. Note that $k[x,y]$ is an integral extension of $A$ since $x$ is a root of $t^2-x^2$. Therefore, $\dim A=2$. Now $\{x^2,y \}$ is a hsop: if $B= k[x^2,y]$, then $A= B1 + Bx^3+Bxy$. 
\end{enumerate}
\end{ex}


\begin{thm}[Noether]
Let $k$ be a field and $A$ be a finitely generated $k$-algebra. Then there exist homogeneous elements $a_1,\ldots,a_d$ which are algebraically independent over $k$ and such that $A$ is a finitely generated module over $k[a_1,\ldots,a_d]$ (which is isomorphic to a polynomial ring). 
\end{thm}

It is worth noting that if $k$ is infinite, then there is a probabilistic algorithm for getting the $a_i$'s. In this case, we could take for the $a_i$'s a `sufficiently general' $k$-linear combination of the generators of $A$. This is Noether's Normalization Lemma. Furthermore, the integer $d$ is uniquely determined; it is the Krull dimension of $A$. In the case that $A$ is an integral domain, $d$ is also the transcendence degree of the field of fractions of $A$ over $k$. 


\begin{dfn}[Cohen-Macaulay (CM)]
If $A= \bigoplus_{i=0}^\infty A_i$ is an $\N$-graded ring with $A_0=k$ a field, then if for some (equivalently, any) hsop $a_1,\ldots,a_d$, $A$ is a free module over the Noether normalization $k[x_1,\ldots,x_d]$, we say that $A$ is Cohen-Macaulay (CM). 
\end{dfn}


\begin{ex} \hfill
\begin{enumerate}[(i)]
\item Let $A:= k[x^2,xy,y^2] \supseteq B:= k[x^2,y^2]$. Observe $A= B1+Bxy$ and $\{1, xy\}$ are $B$-linearly independent. Noting also that $1, xy$ are free generators, i.e. $A$ is free over $B$, we see that $A$ is CM.

\item Let $A:= k[x^2,x^3,y,xy] \supseteq B:= k[x^2,y]$. Observing that $A= B1 + Bx^3+Bxy$ but $y(x^3)-x^2(xy)=0$, we see that $A$ is not CM. 

\item Define $A_1= k[x^4,x^3y,x^2y^2,xy^3,y^4]$ and $A_2= k[x^4,x^3y,xy^3,y^4]$. Only one of these is CM, the other is not. (Which?!)
\end{enumerate}
\end{ex}


\begin{dfn}[Maximal Cohen-Macaulay (MCM)]
Let $A$ be as above and $M$ be a finitely generated $A$-module. We say that $M$ is maximal Cohen-Macaulay (MCM) if for some (equivalently, any) hsop, $M$ is a free module over the Noether normalization. 
\end{dfn}


So $A$ is a CM ring if and only if it is a maximal MCM module over itself. 


\begin{rem}
These are not the typical definitions of CM or MCM. They are equivalent, of course. However, one usually begins by considering the local ring case rather than the graded case. However, we choose this approach for clarity and consistency of approach with the rest of the notes.
\end{rem}


\begin{ex} \hfill
\begin{enumerate}[(i)]
\item Let $A= k[x_1,\ldots,x_d]$ be a polynomial ring and $M$ a finitely generated $A$-module. When is $M$ a maximal Cohen-Macaulay module? We know that $\{x_1,\ldots,x_d\}$ form a hsop. But then $M$ is MCM if and only if it is free over $k[x_1,\ldots,x_d]= A$. Therefore for polynomial rings, the MCM rings are the free modules. 

\item Let $A= k[x^2,xy,y^2]$, and let $I= (x^2,xy)A$ be an ideal of $A$. We claim that $I$ is MCM as an $A$-module. Notice that $I$ is isomorphic to the $A$-submodule of $k[x,y]$ generated by $x$ and $y$. Furthermore, $k[x,y] \cong A \oplus (x,y)A$ as $A$-modules. Notice that $\{x^2,y^2\}$ is a hsop for $k[x,y]$. Since polynomial rings are CM, $k[x,y]$ is a free module $k[x^2,y^2]$-module. Then so too must its summands be free. This shows $(x,y)A$ is a free $k[x^2,y^2]$-module as well. 
\end{enumerate}
\end{ex}


As noted, we have taken a non-standard approach to CM and MCM rings. We shall still need alternative definitions for these concepts in places, so we approach them here.


\begin{dfn}[$M$-Regular]
Let $(A,\fm)$ be a local ring, where $\fm$ is the maximal ideal, and $M$ is a finitely generated $A$-module. A sequence $a_1,\ldots,a_t \in \fm$ is an $M$-regular sequence if
	\begin{itemize}
	\item $a_1$ is a nonzerodivisor on $M$
	\item $a_{i+1}$ is not a zero divisor on $M/(a_1,\ldots,a_i)$ for $i=1,\ldots,t-1$
	\end{itemize}
\end{dfn}


\begin{dfn}[Depth]
Let $(A,\fm)$ be a local ring. The depth of a finitely generated $A$-module $M$ is the length of the longest possible $M$-regular sequence.
\end{dfn}


It is known that the depth $\dep M$ is bounded above by $\dim A$, and $M$ is MCM if and only if equality occurs. 


\begin{thm}[Hochster-Eagon] \label{thm:hocheagon}
Let $G$ be a finite subgroup of $\GL(W)$, and assume $|G| \neq 0$ in $k$. Then the invariant ring $k[W]^G$ is a CM ring. 
\end{thm}

\pf Recall Reynold's operator $\rho: k[W]  \twoheadrightarrow k[W]^G$. Let $f_1,\ldots,f_d$ be a hsop in $k[W]^G$. Let $B= k[f_1,\ldots,f_d]$, $R:= k[W]^G$, and $S:= k[W]$.  Then $B \subseteq R \subseteq S$, and $S$ is a finitely generated $R$-module. But then $S$ is a finitely generated $B$-module. Therefore, $f_1,\ldots,f_d$ form a hsop in $S$. Since polynomial rings are CM, $S$ is a free $B$-module. The Reynold's operator makes $R$ into a direct summand of $S$, as $R$-modules. Hence, the Reynold's operator turns $R$ into a $B$-direct summand of a free $B$-module. Therefore, $R$ is free over $B$, as desired. \qed \\


Note that the assumption on $|G|$ is necessary: if we take $C_4$ act by index permutation on $\F_2[x_1,x_2,x_3,x_4]$, then $\F_2[x_1,\ldots,x_4]^{C_4}$ is not CM. This was shown by Bertin in 1967, see Neusel-Smith. Finally, notice that the proof of Theorem~\ref{thm:hocheagon} holds for any $R$-direct summand of $S$. In other words, writing $S= R \oplus M_1 \oplus \cdots \oplus M_r$ as a direct sum of $R$-modules, then each $M_i$ is a MCM $R$-module. What are the $R$-direct summands of $S$? This is a central question of these notes, which we shall spend most of the remaining text trying to answer. 


Recall that if $\chi: G \to k^\times$ is a linear character, then we have the semi-invariants $k[W]^G_\chi:= \{ f \in k[W] \colon gf= \chi(g)f \; \text{ for all } g \in G\}$. We claim that $k[W]^G_\chi$ is an $R$-direct summand of $k[W]$. Define a `fancy' Reynold's operator $\rho_\chi: k[W] \to k[W]^G_\chi$ by 
	\[
	\rho_\chi(f):= \dfrac{1}{|G|} \sum_{g \in G} \chi(g)^{-1} gf.
	\]
Though it is not immediately obvious, we can show that $\im \rho_\chi \subseteq k[W]^G_\chi$ as follows:
	\[
	\begin{split}
	h \rho_\chi(f)&= \vdots \\
	&= \vdots \\
	&= \text{sum over } h^{-1}g \text{see Reynold's proof} \\
	&= \chi(h) \rho_\chi(f).
	\end{split}
	\]
Furthermore, the map $\rho_\chi$ is $R$-linear and splits the inclusion $k[W]^G_\chi \subseteq k[W]$. In other words, $\rho_\chi$ fixes $k[W]^G_\chi$. This shows that each semi-invariant is an $R$-direct summand of $k[W]$. But that is not all! 



\subsection{Isotypic Components}

Isotypic components are the `jazzy' versions of semi-invariants for higher dimensional representations. Let $\chi: G \to k^\times$ be a linear character and $k[W]^G_\chi$ be its ring of semi-invariants. We know that $G$ acts on the polynomial ring $k[W]$ in a way that preserves degrees. But then $G$ acts on each graded piece $k[W]_t$. By Maschke's Theorem, each $k[W]_t$ decomposes into irreducible representations. Fix an irreducible representation $\rho$, and let $k[W]_\rho^G$ be the direct sum of all appearances of $\rho$ in the decomposition above, each in its appropriate degree. This is the isotypic component of $k[W]$ corresponding to $\rho$. `Obviously', 
	\[
	k[W] \cong \bigoplus_{\rho \text{ irred rep}} k[W]_\rho^G. 
	\]
SO each $k[W]^G_\chi$ is an $R$-module, and by the proof of Theorem~\ref{thm:hocheagon}, this is a MCM $R$-module. Though this technically answers our question, it does not held up gain any deeper understanding. Moreover, are these even all the MCM $R$-modules? If not, how do the other MCM $R$-modules relate to the ones arising in the way above? 


Let $\mcm(R)$ denote the set of all MCM $R$-modules. For any ring $R$ and $A$-module $M$, let $\add_A(M)$ be the set of all direct summands and direct sums of copies of $M$, called the ``additive closure'' of $M$. So far we know that $\add_R(S) \subseteq \mcm(R)$. This begs the question, 
	\[
	\add_R(S) = \mcm(R)?
	\]
If not, can we measure the difference between them? Note that it is a conjecture (the Small CM Conjecture, Hochster) that every complete local ring has a MCM module and has been open since the 1960s. Finally, note that $R \in \add_R(S)$ by use of the Reynold's operator.  


Now let $d= \dim_k W$. In the case that $d=1$, then $\GL(W)= \GL_1(k)= k^\times$, so that $G \subseteq k^\times$, a finite group. But any such group must be cyclic, say then that $G \cong C_n$ is generated by a primitive $n$th root of unity, $\omega$. The action of $\omega$ on $k[W] \cong k[x]$ sends $x$ to $\omega x$. What are the invariants? We know $k[x]^{C_n}= k[x^n]$, which is isomorphic to a polynomial ring. We know that every MCM module over a polynomial ring is free. As a $k[x^n]$-module, $k[x]= \bigoplus_{i=0}^{n-1} k[x^n] x^i$, a free module of rank $n$ with basis $\{1,x,\ldots,x^{n-1}\}$. 


Now let $d=2$. This case includes all finite subgroups of $\SL_2(\C)$. First, we shall need some background on reflexive modules, which are slightly weaker than MCM modules, i.e. there are more reflexive modules than MCM modules. 


\begin{dfn}[Reflexive Module]
Let $A$ be a commutative ring and $M$ be an $A$-module. Define an $A$-module $M^*:= \Hom_A(M,A)$ via $(af)(x)= f(ax)$, where $a \in A$, $x \in M$, and $f: M \to A$ is an $A$-map. 
\end{dfn}


We can then define $M^{**}:=(M^*)^*=\Hom_A(M^*,A)= \Hom_A(\Hom_A(M,A),A)$. However, there is a natural map $\theta_M: M \to M^{**}$ given by $x \mapsto e_x$, where $e_x: \Hom_A(M,A) \to A$ is evaluation at $x$, i.e. $f \mapsto f(x)$. In other words, $\theta_M(x)(f)=f(x)$. We say that $M$ is torsionless if $\theta_M$ is injective. We say that $M$ is reflexive if $\theta_M$ is an isomorphism. In particular, $M^{**} \cong M$. 


\begin{rem}
Torsionless means $\theta_M(x)=0$ is the zero map $M^* \to A$ implies that $x=0$. Equivalently, $f(x)=0$ for all $f: M \to A$ implies that $x=0$. This implies that torsionfree-ness. Recall that $M$ is torsionfree if $x \neq 0$, $a \in A$, a nonzerodivisor implies $ax\neq 0$. If $ax=0$ for some $x \in M$, nonzerodivisor $a$, then $0= f(ax)= af(x)$, for all $f \in M^*$. Since $a$ is a nonzerodivisor, this implies $f(x)=0$ for all $f$. By torsionlessness, we get $x=0$. In fact, the two are equivalent over domains. 
\end{rem}


To discuss reflexivity, we need a bit more about depth. However, we shall only sketch proofs of any of the results here. 


\begin{lem} \label{lem:depth}
Let $(A,\fm)$ be a local ring or a graded ring. Let 
	\[
	0 \ma{} L \ma{} M \ma{} P \ma{} 0
	\]
be a short exact sequence of $A$-modules. Then
	\begin{itemize}
	\item $\dep L \geq \min\{ \dep M, \dep N+1\}$
	\item $\dep M \geq \min\{ \dep L, \dep N\}$
	\item $\dep N = \min\{ \dep M, \dep L-1\}$.
	\end{itemize}
\end{lem}

%\begin{lem}[Depth Lemma]
%\[
%0 \ma{} A \ma{} B \ma{} C \ma{} 0
%\]
%If the above is a short exact sequence of $R$-modules, then
%\begin{enumerate}[(i)]
%\item $\dep_I A \geq \min\{ \dep_I B, \dep_I C+1\}$
%\item $\dep_I B \geq \min\{\dep_I A, \dep_I C\}$
%\item $\dep_I C \geq \min\{\dep_I B,\dep_I A-1\}$
%\end{enumerate}
%\end{lem}
%
%\noindent Proof: The third follows by looking at the exact sequence
%\[
%\cdots \ma{} \Ext_R^{i-1}(R/I,B) \ma{} \Ext_R^{i-1}(R/I,C) \ma{} \Ext_R^i(R/I,A) \ma{} \cdots
%\]
%
%Now if $R$ is noetherian and $M$ is finitely generated, $IM \neq M$, then $x \in I$ is a nonzerodivisor on $M$. We want to show first that $\dep_I(M/xM)=\dep_I M-1$. We use the Depth Lemma:
%\[
%0 \ma{} M \ma{x} M \ma{} M/xM \ma{} 0
%\]
%Then $\dep_I \ov{M} \geq \min\{\dep_I M,\dep_I M-1\}= \dep_I M-1$. For the other inequality, we have a long exact sequence 
%\[
%0=\Ext_R^{t-1}(R/I,M) \ma{} \Ext_R^{t-1}(R/I,M/xM) \ma{} \Ext_R^t(R/I,M) \ma{x} \Ext_R^t(R/I,M)
%\]
%where the last two are nonzero as $t-1 \leq \dep$. Now $x \in I$ kills $\Ext_R^t(R/I,M)$ so that the multiplication by $x$ map is the zero map. Then $0 \to \Ext_R^{t-1}(R/I,M/xM) \to \Ext_R^t(R/I,M) \to 0$ is exact. So they are isomorphic and $\Ext_R^t(R/I,M) \neq 0$ so that $\dep_I M/xM \leq t-1$, as desired. 
%
%Now we show that any two maximal $M$-sequences in $I$ have the same length, namely $\dep_I M$. It is enough to show that any $M$-sequence in $I$ can be extended to one of length $t$. So let $x_1,\cdots,x_k$ be a $M$-sequence in $I$. If $k=0$, we can just find a $M$-sequence of length $t$. On the other hand, if $k>0$, we use our work above. We have $\dep_I(M/(x_1,\cdots,x_k)M)=t-k$ so that we can find a sequence $y_1,\cdots,y_{t-k} \in I$ that is a regular sequence on $M/(x_1,\cdots,x_k)M$. But then $x_1,\cdots,x_k,y_1,\cdots,y_{t-k}$ is a $M$-sequence in $I$ of length $t$. \qed \\




\begin{cor}
If $\dep A \geq 2$, then every $A$-module has depth at least 2.
\end{cor}

\pf Let $M$ be reflexive, and begin a free resolution of the dual $M^*$:
	\[
	A^m \ma{} A^n \ma{} M^* \ma{} 0.
	\]
Now applying $\Hom_A(-,A)$, we obtain the exact sequence
	\[
	0 \ma{} M^{**} \ma{} (A^n)^* \ma{f^*} (A^m)^*.
	\]
Let $C:= \coker f^*$, the Auslander transpose of $M^*$. Then
	\[
	0 \ma{} M \ma{} A^n \ma{f^*} A^m \ma{} C \ma{} 0
	\]
is an exact sequence. By Lemma~\ref{lem:depth}, we must have $\dep M= \dep C+2$ or $\dep M=\dep A$, which are both at least two. \qed \\


This argument can be modified to show that $\dep \Hom_A(M,N) \geq 2$ as long as $\dep N \geq 2$. 


\begin{rem}
This is a special property of `2' since the same does not hold replacing 2s by 3s, 4s, etc.. The proof also shows that any reflexive module over any ring is a kernel of a map homomorphism between free modules, i.e. a second syzygy. 
\end{rem}


\begin{ex}
In the case of CM rings of dimension at least 2, e.g. $A= k[x_1,\ldots,x_n]^G$ with $n \geq 2$, $\dep A \geq 2$. 
\end{ex}

 
 Our next goal will be to show that over normal domains that reflexive modules are precisely second syzygies. 



Serre's Conditions 

\begin{thm}[Serre]
Let $A$ be a noetherian domain. The following are equivalent:
	\begin{enumerate}[(i)]
	\item $A$ is integrally closed in its quotient field, i.e. ``normal''
	\item $A$ satisfies $(R_1)$: $A_p$ is a local domain for all primes of height one. $(S_2)$: $\dep A_p \geq \min\{2, \height p\}$ for all primes $p$. 
	\end{enumerate}
\end{thm}


One can define Serre's condition $(S_k)$ for modules $\dep M_p \geq \min\{k,\dim M_p\}$. An interesting fact is that MCM implies that $(S_k)$ for all $k$. 


\begin{lem} \label{lem:lemhelpful}
Let $f: M \to A$ be a homomorphism of $A$-modules. Assume that $N$ satisfies $(S_1)$ and $M$ satisfies $(S_2)$. Then $f$ is an isomorphism if and only if $f_p: M_p \to N_p$ is an isomorphism for every prime of height at most one. 
\end{lem}


\pf See the notes.


\begin{prop}
Let $A$ be a normal domain and $M$ an $A$-module. Then the following are equivalent:
	\begin{enumerate}[(i)]
	\item $M$ is reflexive
	\item $M$ is a second syzygy
	\item $M$ satisfies $(S_2)$
	\end{enumerate}
\end{prop}


\pf We have already seen that (i) implies (ii). Lemma~\ref{lem:depth} shows (ii) implies (iii). It remains to show that (iii) implies (i). To show that $M$ is reflexive, consider $\theta_M: M \to M^{**}$. Since $M$ satisfies $(S_2)$ and $M^{**}$ is a second syzygy, it also satisfies $(S_2)$. Then $\theta_M$ is an isomorphism if and only if the localization $(\theta_M)_p$ is an isomorphism for all primes $p$ of height at most one. So we localize at a prime $p$ of height one. By Serre's Theorem, $A$ satisfies $(R_1)$ so that $A_p$ is a regular local ring of dimension one. The $A_p$-module $M_p$ has depth one by the $(S_2)$ condition. But then $M_p$ is a MCM module over the regular local ring $A_p$, hence free. Free modules are reflexive so $(\theta_M)_p$ is an isomorphism. \qed \\


The point is that over a (graded) normal domain, MCM modules are reflexive. The converse holds if the ring has dimension at most two. The converse fails in dimension three or more. 


\begin{ex}
Let $A= k[x,y,z]$ and $M$ be the ideal $(x,y)$. We have a short exact srquence
	\[
	0 \ma{} (x,y) \ma{} k[x,y,z] \ma{} \dfrac{k[x,y,z]}{(x,y)} \ma{} 0
	\]
Note that $k[x,y,z]/(x,y) \cong k[z]$, which has depth 1. We know that $k[x,y,z]$ has depth 3. By Lemma~\ref{lem:depth}, we know that $\dep (x,y) \geq \min\{3,1+1\} =2$. We know $1= \dep k[x] \geq \min\{3,\dep(x,y)-1\}$. But then $\dep (x,y)=2$. In particular, $(x,y)$ is a reflexive $A$-module by the Proposition. It is not MCM because it is not free. 
\end{ex}


\begin{ex}
Let $A= k[x,y,z]$ and $M= (x,y)$. We have the short exact sequence
	\[
	0 \ma{} (x,y) \ma{} A \ma{} \dfrac{A}{(x,y)} \ma{} 0.
	\]
We know $A/(x,y) \cong k$, a field, so this has depth 0. We know that $\dep A=2$. Then it must be that $\dep (x,y)=1$. So $(x,y)$ is neither reflexive nor MCM. What is $M^{**}$? Consider the free resolution
	\[
	A \ma{} A \oplus A \ma{} (x,y) \ma{} 0
	\]
with maps $a \mapsto (y,-x)$ and $(a,b) \mapsto ax+by$. Taking duals yields,
	\[
	0 \ma{} (x,y)^* \ma{} (A \oplus A)^* \ma{i^*} A^*
	\]
Now $i^*(e_1)$ (the first coordinate function) is $i^*(e_1)=e_1i=y$ and $i^*(e_2)=e_2i= -x$. Then $i^*$ is the map $(a,b) \mapsto ay-bx$ and further $(x,y)^* \cong \ker i^* \cong A(x,y) \cong A$. But $(x,y)^{**} \cong A^* \cong A$. 

% Rewrite
%	\[
%	0 \ma{} A \ma{(y\;-x)^T} A \oplus A \ma{(x\;y)} A
%	\]
%Dualizing gives
%	\[
%	0 \ma{} (x,y)^* \ma{} A \oplus A \ma{(y\;-x)} A
%	\]
%$\ker [y\;-x]= \ker [x\;y]=A$. 
\end{ex}


\begin{thm}[Herzog, 1978]
Let $S= k[u,v]$, $G \subseteq \GL_2(k)$ a finite group with $|G| \in k^*$. Set $R= \widehat{S^G}$, the completion of the invariant ring. Then every indecomposable MCM $R$-module is a direct summand of $\hat{S}= k\llbracket u,v \rrbracket$.
\end{thm}

\pf We shall assume the Krull-Schmidt property for $R$ and $S$, and leave the details passing between the ring and its completion for the reader. Let $M$ be an indecomposable MCM (reflexive) $R$-module. We want $M$ to be a direct summand of $S$ as an $R$-module. Since $|G| \in k^\times$, we have the Reynold's operator, so $R$ is a direct summand of $S$ as $R$-modules. So we have the split monic $R \hookrightarrow S$. Apply $\Hom_R(M^*,-)$. Then we have $\Hom_R(M^*,R) \to \Hom_R(M^*,S)$ still splits. However, $\Hom_R(M^*,R)=M^{**} \cong M$ as $M$ is reflexive. The $R$-module $\Hom_R(M^*,S)$ is naturally an $S$-module: $(sf)(\lambda):= s(f(\lambda))$ for $s \in S$, $f: M^* \to S$, $\lambda \in M^*$. Furthermore, we have proved that $\Hom$ modules have depth $\geq 2$. So $\Hom_R(M^*,S)$ is an $S$-module of depth 2, hence an MCM $S$-module, hence free. So $M$ is a direct summand over $R$ of a free $S$-module. $M \mid S^n$ for some $n$. But $M$ is indecomposable, and we have Krull-Schmidt, so $M$ must be a direct summand of $S$, i.e. $M \mid S$, which is what we wanted to show. \qed \\


\begin{rem}
We need the `hats' in order to use the Krull-Schmidt uniqueness theorem for direct-sum decompositions. This fails even for $k[u,v]$. Could get away with much less, the Hensalization for example. 
\end{rem}


\begin{cor}
For 2-dimensional rings of invariants $R= S^G$. $\add_R(S)=MCM(R)$.
\end{cor}



\begin{ex}
Let $C_n= \langle \sigma \colon \sigma^n=1 \rangle$ act on $S= k[u,v]$ via $\sigma(x)= \omega_n x$, $\sigma(y)= \omega_n^{-1}y$, i.e. 
	\[
	\sigma = \two{\omega_n}{}{}{\omega_n^{-1}} \in \SL_2(k).
	\]
Then $R= S^G= k[u^n,u^{n-1}v, \ldots, v^n]$ (we worked this out before). Furthermore, we worked out $S \cong_{R-mod} R \oplus I_1 \oplus I_2 \oplus \cdots \oplus I_{n-1}$, where $I_j$ is generated as an $R$-module by monomials of degree $j \mod n$. Explicitly, $I_j= (u^j,u^{j-1}v,\ldots,v^j) R \cong (u^jv^{n-j}, u^{j-1}v^{n-j+1}, \ldots, v^n)$. By Herzog's Theorem, every maximal MCM (or reflexive) can be written $R^{a_0} \oplus I_1^{a_1} \oplus I_2 \oplus \cdots \oplus I_{n-1}^{a_{n-1}}$.
\end{ex}


\begin{dfn}
We say that a (local or graded) ring $A$ has finite CM representation type (fCMt) if it has finitely many indecomposable MCM modules up to isomorphism. 
\end{dfn}


\begin{cor}
$k[u,v]^G$ have fCMt. 
\end{cor}


Note that Herzog's Theorem does not hold in dimension greater than two. 

\begin{ex}
Let $C_2= \{\pm 1\}$ act on $k[x,y,z]$. Then $R= k[x^2,y^2,z^2,xy,xz,yz]$. As $R$-modules, $S$ has rank 2 (by previous work) $S \cong R \oplus I$, where $I$ is all monomials of odd degree, i.e. $(x,y,z)R \cong (x^2,xy,xz)R$. Take a syzygy of $I$: 
	\[
	0 \ma{} N:= \ker \pi \ma{} R^3 \ma{\pi} I \ma{} 0
	\]
FACT: Another theorem of Herzog coming soon. $N$ is indecomposable. [Theorem says it is a syzygy of an indecomposable MCM module. So $N$ is an indecomposable MCM module of rank 2, hence it is not isomorphic to either $R$ or $I$, so does not appear as a summand of $S$ (technically, this requires Krull-Schmidt). 
\end{ex}



\subsection{The Gorenstein and Isolated Singularity Properties}


Goal is to determine when invariant rings have these properties, then use them in Auslander version of the \mc Correspondence. 


\begin{dfn}[Gorenstein]
Let $A= A_0 \oplus A_1 \oplus \cdots \oplus A_s$ be a graded algebra over $A_0=k$, a field. Assume that $A_s=0$ but $A_{>s}=0$. Say that $A$ is Gorenstein (or a Poincar\'e duality algebra) if $A_s \cong k$ is a 1-dimensional vector space and for every $i$, the mapping $A_i \times A_{s-i} \to A_s \cong k$ given by $(a,a') \mapsto aa'$ is a perfect pairing. [Recall a bilinear map $\langle, \rangle: V \times W \to k$ is a perfect pairing if the induced map $V \to W^\vee:= \Hom_k(W,k)$ is an isomorphism of vector spaces, where the induced map is given by  $v \mapsto \langle v, - \rangle: W \to k$.] 
\end{dfn}


In particular, if $A$ is Gorenstein, then $A_i^\vee \cong A_{s-i}$. By the way, this is equivalent to the usual definition that $\soc A= \{a \colon a A_{\geq 1}=0 \}$ is 1-dimensional. Notice $A_s$ is always in $\soc A$, and if $\soc$ were to contain any elements of degree $i \neq s$, say $a$, then the map $A_i \to A_{s-i}^\vee$ given by $v \mapsto \mu_v$, multiplication by $v$, would have $a$ in the kernel so that it would not be an $\cong$. 



Bookkeeping devices: For a graded ring $A= \bigoplus_{i=0}^\infty A_i$ where $A_0=k$, the Hilbert function counts vector space dimensions, $H_A(n) \stackrel{def}{=} \dim_k A_n$. One can do this for modules also, $H_M(n) \stackrel{def}{=} \dim_k M_n$. If now $A= A_0 \oplus \cdots \oplus A_s$ is a finite dimensional Gorenstein ring, then $A_i \cong A_{s-i}^\vee$ so they have the same $k$-dimension, so $H_A(i)= H_A(s-i)$, where $i=0,\ldots,s$. That is, the Hilbert function is symmetric. Caution: symmetric hilbert function does not imply gorenstein. Note also $\sum_i H_A(i)= \dim_k( \oplus A_i)= \dim_k A$. The Hilbert series of $A$ is the generating function for its Hilbert function $h_A(t)= \sum_{n \geq 0} H_A(n) t^n$. Notice that $h_A(t)$ is a polynomial if and only if $A_i=0$ for $i \gg 0$ if and only if $\dim_k A< \infty$. 


\begin{thm}[Hilbert]
For $n \gg 0$, $H_A(n)$ agrees with a polynomial $P_A(n)$ of degree $\dim A+1$, called the Hilbert polynomial. In particular, $h_A(t)$ is a rational function of $t$. 
\end{thm}


Again let $A$ be a finite dimensional Gorenstein graded ring. Since the Hilbert function is symmetric, $h_A(t)= h_0 + h_1t + h_2t^2+ \cdots + h_st^s$ with $h_i= H_A(i)$ and $h_i= h_{s-i}$. Then 
	\[
	h_A(1/t) = t^{-s} h_A(t).
	\]


\begin{ex}
$A= k[x,y]/(x^2,y^2)= k \oplus \langle x,y \rangle \oplus \langle xy \rangle$. So $s=2$. The bilinear map $A_1 \times A_2 \to A_2$ is a perfect pairing, so $A$ is Gorenstein. $h_A(t)= 1+2t+t^2$, so $h_A(1/t)= 1+2/t+1/t^2= 1/t^2(1+2t+t^2)$. 
\end{ex}


\begin{ex}
$A= k[x,y]/(x^2,xy,y^3)$. $H_A: (1,2,1)$ same Hilbert function as previous example but $A$ is not Gorenstein since $x$ kills all terms in degree 1, $xA_{\geq 1}= 1$ but $x$ does not have degree 2=s. 
\end{ex}



\subsection{Module-Theoretic Properties of Gorenstein Rings}

Observe that for any finite dimensional graded algebra $A$, the $k$-dual $A^\vee= \Hom_k(A,k)$ is an injective $A$-module. This follows directly from $\Hom - \otimes$ adjointness, we want ot show $\Hom_A(-,A^\vee)$ is exact. But $\Hom_A(-,A^\vee)= \Hom_A(-, \Hom_k(A,k))= \Hom_k(-\otimes_A A,k)= \Hom_k(-,k)$, which is exact. 
	\[
	A^\vee = \Hom_k(A,k) = \Hom_k( \oplus_{i=0}^s A_i,k) = \oplus_{i=0}^s \Hom_k(A_i,k) \cong \oplus_{i=0}^s A_{s-i}
	\]
So $A^\vee \cong A$ as vector spaces. One can check that $A^\vee \cong A$ as $A$-modules. The upside is that a Gorenstein finite dimensional algebra is self injective, i.e. injective as a module over itself. The converse is also true: sketch: show $A^\vee= \Hom_k(A,k)$ is the injective hull of $k$, since $A$ is self-injective and contains $k$, conclude $A \cong A^\vee$. 

It follows that if $A$ is Gorenstein, then every finitely generated $A$-module is torsionless and in fact is reflexive. Sketch: Start with $k= A/A_{\geq 1}$. We have $k^*= \Hom_A(k,A)= \ann_A A_{\geq 1}= \soc A \cong k$, where the last isomorphism follows since $A$ is Gorenstein. So $k^{**} \cong k$ also, and we just have to show $k \to k^{**}$ is not zero. Then finish by induction on $\dim_k M$. 



%%%%%%%%%%%%



\begin{dfn}
A graded algebra $A= \oplus_{i=0}^\infty A_i$ with $A_0=k$ a field is called Gorenstein if there is a regular sequence $x_1,\ldots,x_d$, of elements of positive degree so that $\overline{A}:= A/(x_1,\ldots,x_d)$ is a finite dimensional Gorenstein ring. Note $d$ is necessarily $\dim A$. 
\end{dfn}


Equivalently, though we we will not prove this, the quotient $A/(x_1,\ldots,x_d)$ is a finite-dimensional Gorenstein ring for every regular sequence $x_1,\ldots,x_d$. How do Hilbert series behave when we kill a regular sequence? 


\begin{prop}
Let $A$ be a graded ring and $x \in A$ a homogeneous element of degree $e>0$. Then
	\[
	h_A(t)= \dfrac{h_{A/(x)}(t) - t^e h_{\ann x}(t)}{1 - t^e}
	\]
\end{prop}

In particular, $x$ is a nonzero divisor if and only if $h_{A/(x)}(t)= (1-t^e) h_A(t)$.


The ``in particular'' is clear by subsitution, get zero, but that's the sum of dimensions of graded pieces so must be zero ring?


For the rest, consider a more general situation. Let
	\[
	0 \ma{} L \ma{} M \ma{} N \ma{} 0
	\]
be an exact sequence of graded $A$-modules and homogeneous maps of degree zero so $L_i \hookrightarrow M_i$, $M_i \twoheadrightarrow N_i$. Then for each degree $n$, we get
	\[
	0 \ma{} L_n \ma{f_n} M_n \ma{g_n} N_n \ma{} 0
	\]
is an exact sequence of vector spaces. But then we can easily calculate dimensions. Then $\dim_k M_N= \dim_k L_n + \dim_k N_n$. Or in terms of Hilbert functions, $H_M(n)= H_L(n) + H_N(n)$ so that $h_M(t)= h_L(t) + h_N(t)$. 


Now assume that $f$ and $g$ are homogeneous of degrees $a$ and $b$, respectively, i.e. $f(L_n) \subseteq M_{n+a}$, $g(M_N) \subseteq N_{n+b}$. Then for each $n$, we get a short exact sequence 
	\[
	0 \ma{} L_n \ma{f_n} M_{n+a} \ma{g_{n+a}} N_{n+a+b} \ma{} 0
	\]
Then 
	\[
	H_L(n) - H_M(n+a) + H_N(n+a+b) = 0 
	\]
Now
	\[
	\sum_n H_M(n+a)t^n = t^{-a} \sum_n H_M(n+a) t^{n+a} = t^{-a} h_M(t)
	\]
So that
	\[
	h_L(t) - t^{-a} h_M(t) + t^{-a-b} h_N(t) = 0 
	\]
Long exact sequences give similar alternating sums. 


Proof of Prop: We have the exact sequence
	\[
	0 \ma{} \ann(x) \ma{i} A \ma{x} A \ma{\pi} A/(x) \ma{} 0
	\]
where $\deg i=0$, $\deg x= e$, $\deg \pi = 0$. Then we get exact sequences
	\[
	0 \ma{} \ann(x)_n \ma{} A_n \ma{} A_{n+e} \ma{} (A/(x))_{n+e} \ma{} 0
	\]
of vector spaces. By above, we get
	\[
	h_{\ann x}(t) - h_A(t) + t^{-e} h_A(t) - t^{-e} h_{A/(x)}(t) = 0
	\]
Multiplying by $t^e$ and juggling, 
	\[
	(1-t^e) h_A(t) = h_{A/(x)}(t) - t^e h_{\ann x}(t)
	\]
\qed \\




\begin{cor}
Le t$A$ be as above and $x_1,\ldots,x_c$ be homogeneous elements of positive degrees $e_1,\ldots,e_c$. Then we have a coefficient-wise inequality of power series 
	\[
	h_A(t) \preccurlyeq \dfrac{h_{A/(x_1,\ldots,x_e)}(t)}{\prod_{i=1}^c (1-t^{e_i})}
	\]
with equality if and only if $x_1,\ldots,x_c$ is a regular sequence. 
\end{cor}


\begin{ex}
We can compute the Hilbert series for any complete intersection: $A= k[x_1,\ldots,x_n]/(f_1,\ldots,f_c)$, where $\deg x_i = d_i$, $\deg f_i= e_i$, and $f_1,\ldots,f_c$ is a regular sequence. First, let $S= k[x_1,\ldots,x_n]$ with $\deg x_i= e_i$. Then $x_1,\ldots,x_n$ is an $S$-regular sequence with $S/(x_1,\ldots,x_n)= k$. So 
	\[
	h_S(t) = \dfrac{h_k(t)}{\prod_{i=1}^n (1-t^{d_i})}
	\]
Then $h_A(t) = h_{S/(f_1,\ldots,f_c)}= h_S(t) \prod_{j=1}^c (1-t^{e_j})= \dfrac{\prod_{j=1}^c (1-t^{e_j})}{\prod_{i=1}^n (1-t^{d_i})}$. 
\end{ex}


\begin{prop}
Let $A$ be a Gorenstein graded ring of Krull dimension $d$. Then $h_A(1/t)= (-1)^d t^a h_A(t)$ for some integer $a$. 
\end{prop}

\pf Let $x_1,\ldots, x_d$ be a regular sequence so that $\overline{A}= A/(x_1,\ldots,x_d)= \overline{A}_0 \oplus \cdots \oplus \overline{A}_s$ is a finite dimensional Gorenstein algebra. Let $e_i = \deg x_i$. Then we know 

\begin{enumerate}[(i)]
\item $h_A(t) = \dfrac{h_{\overline{A}}(t)}{\prod_{i=1}^d (1-t^{e_i})}$
\item $h_{\overline{A}}(1/t) = t^{-s} h_{\overline{A}}(t)$
\end{enumerate}

So $h_A(1/t)= \dfrac{h_{\ov{A}}(1/t)}{\prod_{i=1}^d (1- (1/t)^{e_i})}= \dfrac{t^{-s} h_{\ov{A}}(t)}{t^{-e_1-e_2-\cdots-e_d} \prod_{i=1}^d (t^{e_i}-1)}= (-1)^d t^{s+e_1+\cdots+e_d} h_A(t)$ \qed \\


\begin{rem}
We know that the formula $h_A(1/t) = (-1)^d t^a h_A(t)$ follows from the Gorenstein property, but is not equivalent (even when $d=0$). Stanley proved that the two are equivalent when $A$ is a CM domain. We will not prove this. 
\end{rem}


Back to invariant theory. So $S= k[x_1,\ldots,x_n]$, $G \subseteq \GL_n(k)$ finite with $|G| \in k^\times$ and $R= S^G$. We will assume $k$ is algebraically closed.

\begin{dfn}
The Hilbert series of $R$ is called the Molien series of $G$.
	\[
	M_G(t) = h_R(t)
	\]
\end{dfn}

We will compute $M_G(t)$ in terms of $G$. More generally, the Molien series of a linear character $\chi: G \to k^\times$ is the Hilbert series of the semi-invariants
	\[
	R_\chi = S_\chi^G= \{ f \in S \colon gf= \chi(g)f \}
	\]
These are graded subsets of $S$. 
	\[
	M_\chi(t) = \sum_{i \in \Z} \dim_k(R_\chi)_i t^i
	\]
If $\chi$ is trivial, then $M_{\text{triv}}(t) = N_G(t)$. 

\begin{rem}
One can also do this for isotypic components but we will not. 
\end{rem}


So we want to compute $\dim_k(R_\chi)_i$. Recall that we have the fancy Reynold's operators $\rho_\chi: S \to S$ given by $f \mapsto \dfrac{1}{|G|} \sum_{g \in G} \chi(g)^{-1} gf$ with image $R_\chi$, and $(\rho_\chi)^2= \rho_\chi$. These properties preserve degrees, so we get linear maps $(\rho_\chi)_i: S_i \to S_i$ with image $(R_\chi)_i$. We can choose bases for $S_i$ so that $(\rho_\chi)_i$ is in rank normal form: $\two{I}{0}{0}{0}$. Then $\dim_k(R_\chi)_i = \dim_k(\im(\rho_\chi)_i)= \text{trace}((\rho_\chi)_i)$. PLug in the formula for $\rho_\chi$: $\dim(R_\chi)_i= \dfrac{1}{|G|} \sum_{g \in G} \chi(g)^{-1} \text{trace}(g|_{S_i})$.


\begin{thm}[Molien]
	\[
	M_\chi(t) = \dfrac{1}{|G|} \sum_{g \in G} \dfrac{\chi(g)^{-1}}{\det(I-tg)}
	\]
In particular,
	\[
	M_G(t) = \dfrac{1}{|G|} \sum_{g \in G} \dfrac{1}{\det(I-tg)}
	\]
\end{thm}


\begin{ex}
$R= k[u,v]^{C_2}= k[u^2,uv,v^2] \cong k[x,y,z]/(xz-y^2)$, $C_2= \left\{ \two{1}{0}{0}{1}, \two{-1}{0}{0}{-1} \right\}$. 


Then $M_G(t) = \dfrac{1}{2} \left( \dfrac{1}{\det(I-tI)} + \dfrac{1}{\det(I+tI)}\right)$ which is $\dfrac{1}{2} \left( \dfrac{1}{(1-t)^2} + \dfrac{1}{(1+t)^2} \right)$. which is
	\[
	\dfrac{1+t^2}{(1-t^2)^2}
	\]
which is also the Hilbert series of $k[x,y,z]/(f)$ with $\deg x= \deg y= \deg z=2$, $\deg f= 4$
	\[
	\dfrac{1-t^4}{(1-t^2)^3}= \dfrac{1+t^2}{(1-t^2)^2}
	\]
We had to use those degrees to get a graded isomorphism. 
\end{ex}


We will now focus on the case where $\chi=$ triv, so we want
	\[
	h_R(t) = M_G(t) = \dfrac{1}{|G|} \sum_{g \in G} \dfrac{1}{\det(I-tg)}
	\]
We computed $\dim_k R_i= \dfrac{1}{|G|} \sum \text{tr}(g\big|_{S_i})$. So we know that $M_G(t)= \sum_k \dim_k(R_i) t^i= \dfrac{1}{|G|} \sum_i \sum_{g \in G} \text{tr}(g \big|_{S_i}) t^i$. Then it suffices to show that 
	\[
	\dfrac{1}{\det(I-tg)}= \sum_{i=0}^\infty \text{tr}(g\big|_{S_i}) t^i
	\]
for each $g \in G$. So fix $g \in G$. Since $G$ is finite, $g$ has finite order. The formula is true for all $g \in \GL_n(k)$, but finite order makes the proof simpler. In particular, if $g^r= I$, then the minimal polynomial of $g$ divides $x^r-1$. The roots of $x^r-1$ are distinct since $\char k \nmid |G|$ (note that if $\char k \mid r$, then $\char k \mid G$ since $r \mid G$). Therefore, the eigenvalues of $g$ are distinct. But then $g$ is diagonalizable. We may assume $g= \text{diag}(\lambda_1,\ldots,\lambda_n)$, where $\lambda_i$ are the eigenvalues. In particular, $gx_i = \lambda_i x_i$ for each $x_i \in S= k[x_1,\ldots,x_n]$. The $i$th graded piece $S_i$ has basis
	\[
	\left\{ x_1^{a_1} x_2^{a_2} \cdots x_n^{a_n} \colon a_1 + \cdots + a_n \right\}.
	\]
The action of $g$ on $S_i$ sends that basis vector to $\lambda_1^{a_1} \cdots \lambda_n^{a_n} x_1^{a_1} x_2^{a_2} \cdots x_n^{a_n}$. So the action of $g$ on $S_i$ is also diagonal and
	\[
	\text{tr}(g\big|_{S_i}) = \sum_{a_1+\cdots+a_n= i} \lambda_1^{a_1} \cdots \lambda_n^{a_n}.
	\]
So now we use the geometric series:
	\[
	\begin{split}
	\sum_{i=0}^\infty \text{tr}(g\big|_{S_i}) t^i &= \sum_{i=0}^\infty \sum_{a_1+\cdots+a_n= i } \lambda_1^{a_1} \cdots \lambda_n^{a_n} t^i \\
	&= \sum_{i=0}^\infty \sum_{a_1+\cdots+a_n= i} (\lambda_1^{a_1} t^{a_1})(\lambda_2^{a_2} t^{a_2}) \cdots (\lambda_n^{a_n} t^{a_n}) \\
	&= \sum_{i=0}^\infty \sum_{a_1+\cdots+a_n= i} (\lambda_1t)^{a_1} (\lambda_2 t)^{a_2} \cdots (\lambda_n t)^{a_n} \\
	&= \dfrac{1}{1-\lambda_1t} \, \dfrac{1}{1-\lambda_2t} \, \cdots \, \dfrac{1}{1-\lambda_nt} \\
	&= \dfrac{1}{\prod_{j=1}^n (1-\lambda_jt)} 
	\end{split}
	\]
Now 
	\[
	\prod_{j=1}^n (1- \lambda_jt)= \dfrac{\prod_{j=1}^n \lambda_j^{-1}}{\prod_{j=1}^n (\lambda_j^{-1} -t)}= \dfrac{\det(g^{-1})}{\deg(g^{-1}-tI)} \cdot \dfrac{\det g}{\det g}= \dfrac{1}{\det(I-tg)}
	\]
\qed \\


%\begin{ex}
%$G= C_3$, generated by $\two{\omega}{0}{0}{\omega^2}$, where $\omega$ is a primitive cube root of 1. So $R= k[u,v]^{C_3} = k[ u^3,uv,v^3] \cong k[x,y,z]/ (xz-y^3)$. By the equation $\sum_{g \in G} \text{tr}(g \big|_{S_i}) t^i$, 
%	\[
%	M_G(t)= \dfrac{1}{3} \left( \dfrac{1}{\det(I-tI)} + \dfrac{1}{\det\left(I - \two{t\omega}{0}{t\omega^2}} + \dfrac{1}{\det\left(I - \two{t\omega^2}{t\omega}\right)} \irhgt)= \dfrac{1}{3} \left( \dfrac{1}{(1-t)^2} + \dfrac{2}{(1-t\omega)(1-t^2\omega)}}= \dfrac{1-t+t^2}{(1-t)(1-t^3)}. 
%	\]
%\end{ex}


\begin{ex} Using Molien's formula to compute invariants
Let 
	\[
	G= \left\{ \two{\pm 1}{}{\pm 1}, \two{\pm i}{0}{\mp i}, \two{0}{\pm i}{\pm i}{}, \two{}{\pm 1}{}{\pm1} \right\} = Q_8
	\]
What is $k[u,v]^G$? Molien's fomula says
	\[
	h_R(t) = \dfrac{1}{8} \left( \dfrac{1}{(1-t)^2} + \dfrac{1}{(1+t)^2} + \dfrac{6}{1+t^3} \right)= \dfrac{1+t^6}{(1-t^4)^2}= 1 + 2 t^4 + t^6 + \cdots
	\]
So $R$ contains 2 linearly independent polynomials of degree 4 and 6. After a brief such, $u^2v^2$ and $u^4+v^4$ are invariant. Since they're invariant, so is their Jacobian so that $u^5v - uv^5 \in R_6$. Set $X= u^4+v^4$, $Y= u^2v^2$, and $Z= u^5-uv^5$. These must then live inside: so $k[X,Y,Z] \subseteq R = k[u,v]^G$. Any 3 polynomials in $k[u,v]$ have some defining relation so can cretae that $Z^2 = X^2Y-4Y^3$. So $A= k[X,Y,Z] \cong k[y,z,]/(z^2-x^2y+4y^3)$. Then $h_A(t)= \dfrac{1-t^{1/2}}{(1-t^4)^2(1-t^6)} = \dfrac{1}{t^6}{(1-t^4)^2} = h_R(t)$. But then $A=R$. Finally when $S^G$ is gorenstein, recall a pseudo-reflection is an $n \times n$ matrix of finite order having 1 as an eigenvalue of multiplicity $n-1$.
	\[
	g= \begin{pmatrix}
	1 & 1 & \cdots \\
	& 1 & \\
	& \ddots &  \\
	& & \lambda
	\end{pmatrix}, \quad \lambda^r=1.
	\]
\end{ex}





\begin{thm}[Stanley, Watanabe]
Let $G \subseteq \GL_n(k)$ be a finite subgroup with $|G| \in k^\times$. Then $R= k[x_1,\ldots,x_n]^G$ is gorenstein if and only if
	\[
	\sum_{g \in G} \dfrac{1}{\det(I-tg)}= t^{-m} \sum_{g \in G} \dfrac{\det g}{\det(I-tg)}
	\]
where $m$ is the number of pseudo-relections in $G$. In particular, when $G$ is small (i.e. $m=0$), then $R$ is Gorenstein if and only if $G \subseteq \SL_n(k)$.
\end{thm}

\pf We will use fact that since $R$ is a domain, $R$ is gorenstein if and only if
	\[
	h_A(1/t) = (-1)^d t^a h_A(t)
	\]
for some $a \in \Z$. Plug in our formula for $h_R(t)= M_G(t)$
	\[
	\dfrac{1}{|G|} \sum_{g \in G} \dfrac{1}{\det(I-tg)} = h_R(t) = (-1)^d t^{-a} h_R(1/t)= \dfrac{1}{|G|} (-1)^d t^{-a} \sum_{g \in G} \dfrac{1}{\det(I-t^{-1}g)} \cdot \dfrac{t \deg(g)^{-1}}{t (\det g)^{-1}}  = \dfrac{1}{|G|} (-1)^d t^{-a+n} \sum_{g \in G} \dfrac{\det g}{\det(I-tg)}
	\]

Now
	\[
	\sum_{g \in G} \dfrac{1}{\det(I-t^{-1}g)}= (-1)^n \sum_{g \in G} \dfrac{1}{\det(t^{-1}g-I)} = (-1) \sum_{g \in G} \dfrac{\deg(g)^{-1}}{\det(t^{-1}I-g^{-1})}= (-1) \sum_{g \in G} \dfrac{\det g}{\det(t^{-1}I-g)} = (-1) t^n \sum_{g \in G} \dfrac{\det g}{\det(I-tg)}
	\]
So
	\[
	\sum_{g \in G} \dfrac{1}{\det(I-tg)} = t^{-a+n} \sum_{g \in G} \dfrac{\det g}{\det(I-tg)}
	\]
up to sign. So we need to just identify $m= a-n$ as the number of pseudo-reflections. Expanding both sides of the above as Laurent series in $1-t$. Recall that a Laurent series $\dfrac{c_r}{(1-t)^r} + \dfrac{c_{r-1}}{(1-t)^{r-1}} + \cdots$ with $c_r \neq 0$ has a pole of order $r$ at $t=1$. We know each term $\dfrac{1}{\det(I-tg)}$ is equal to 
	\[
	\dfrac{1}{\prod_{j=1}^n (\lambda_j-t)}
	\]
since $g$ is diagonalizable and $k= \overline{k}$. We need to know the multiplicity of 1 as an eigenvalue---that will be the order of the pole at $t=1$. The biggest the multiplicity can be is $n$, when $g= I$, if and only if $g=I$. The next biggest is $n-1$ if and only if $g$ is a pseudo-reflection. So 
	\[
	\sum_{g \in G} \dfrac{1}{\det(I-tg)}= \dfrac{1}{(1-t)^n} + \sum_{g \text{ps ref}} \dfrac{1}{(1-t)^{n-1} (\det g - t)} + \text{h.o.t.}= \dfrac{1}{(1-t)^n} + \dfrac{1}{(1-t)^{n-1}} \sum_{g \text{ps}} \dfrac{1}{\det g - t} + \text{h.o.t.}
	\]
To get this in terms of only $(1-t)$, we need
	\[
	\dfrac{1}{(1-t)^{n-1}} \sum_{g \text{ps}} \dfrac{1}{\det g-t}= \dfrac{c_{n-1}}{(1-t)^{n-1}} + \dfrac{c_{n-2}}{(1-t)^{n-2}} + \cdots 
	\]
To solve for $c_{n-1}$, multiply by $(1-t)^{n-1}$ and plug in $t=1$.
	\[
	\sum_{g \text{psd}} \dfrac{1}{\det g-1}= c_{n-1}
	\]
and that is equal to $\sum_{g \text{psd}} \dfrac{1}{1-\det g}$. On the left hand side, we have 
	\[
	\dfrac{1}{(1-t)^n} + \dfrac{1}{(1-t)^{n-1}} + \sum_{g \text{psd}} \dfrac{1}{1-\det g} + \text{h.o.t.}
	\]
The right hand side is, using $t^{-m}= \left(\dfrac{1}{t}\right)^m = \left(\dfrac{1}{1-(1-t)} \right)^m = \left( \sum_{i=0}^\infty (1-t)^i \right)^m= (1+(1-t)+(1-t)^2+\cdots)^m= 1+ m(1-t) + \cdots$
	\[
	t^{-m} \sum_{g \in G} \dfrac{\det g}{\det(I-tg)} = (1+m(t-1)+\cdots) \cdot (\dfrac{1}{(1-t)^n} + \dfrac{1}{(1-t)^{n-1}} \sum_{g \text{psd}} \dfrac{\det g}{1-\det g} + \cdots)
	\]
The coefficient of $\dfrac{1}{(1-t)^{n-1}}$ in this product is $m+ \sum_{g \text{psd}} \dfrac{\det g}{1-\det g}$. Now we are done by comparing coefficients we obtain that 
	\[
	\sum_{g \text{psd}} \dfrac{1}{1-\det g} = m + \sum_{g \text{psd}} \dfrac{\det g}{1-\det g}
	\]
Moving over left sum, obtain
	\[
	\sum_{g \text{psd}} 1= m 
	\]
so that $m$ is the number of pseudo-reflections. \qed \\


For the last sentence, we just need to show that $\sum_{g \in G} 1 = \sum_{g \in G} \det g$ if and only if $\det g=1$ for all $g$. If $\det g=1$, then simple. For the other direction, recall $\det g$ is a root of unity. So then must be all 1 since add to 1. 




%%%%%%%%%%%%%%%%%%%%%%%


\begin{cor}[Watanabe]
If $G \subseteq \SL_n$, then $R$ is Gorenstein. Furthermore, if $G$ is small, then the converse holds.
\end{cor}

\pf If $G \subseteq \SL_n$, then $\det g=1$ for all $g \in G$. There are no pseudo-reflections in $\SL$. In particular, there are no pseudo-reflections in $G$. The last part was done above (all parts of $G$ are roots of unity). \qed \\


% End of a long chapter

When is $R= k[W]^G$ an isolated singularity? Postpone this until ramification theory. (Answer: when no $g \in G \setminus \{1\}$ has 1 for an eigenvalue, which is stronger than no pseudo-reflections.)


Recall our goal is to understand the direct summands of $S= k[W]$ as an $R$-module (they are all MCM modules) and the structure of

1) the maps between them
2) the relationship with the rest of the $R$-modules.

Main tool: the skew group algebra (twisted group ring, smash product, \dots)

Let $S$ be a commutative ring (lose nothing by pretending $S= k[W]$) and $G$ be a group acting on $S$ by automorphisms. The skew group algebra $S\#G$ is an $S$-module, free on the elements of $G$, so the elements of $S\#G$ are formal sums $\sum_{g \in G} s_g \cdot g$, where $s_g \in S$ for all $g \in G$. The action is $(s \cdot g)(t\cdot h)= sg(t)gh$ for $s,t \in S$ and $g,h \in G$. So moving $g$ past $t$ twisted the ring element. Why? Patience. What are the $S\#G$ modules?


Notice $S$ sits inside $S\#G$ as $\{s \cdot 1_G\}$ as a subring. So $S\#G$ is an $S$-algebra. In particular, any $S\#G$-module $M$ is an $S$-module by restriction of scalar. On the other hand, $G$ also sits inside $S\#G$ as $\{1_s \cdot g\}$. So $M$ comes with a $G$-action $g(x)= (1_s \cdot g)x$, $x \in M$, $g \in G$. So $S\#G$-module is an $S$-module with an action of $G$. That action is compatible with the $S$-module structure: 
	\[
	\begin{split}
	g(sx)&= g((s1)x) \\
	&= (1g)(s1)x \\
	&= (g(s)g)x \\
	&=(g(s)1)(1g)x \\
	&= g(s)g(x)
	\end{split}
	\]
Conversely, an $S$-module $M$ with an action of $G$ that satisfies $g(sx)=g(s)g(x)$ is an $S\#G$-module.

\begin{rem}
This allows us to talk about the invariants of an $S\#G$-module, namely $M^G:= \{ x \in M \colon gx=x \}$. Also notice that $S$ itself is an $S$-module with a compatible $G$-action. So we can consider $S^G$.
\end{rem}

Similarly, an $S\#G$-homomorphism between $S\#G$-modules $M,N$ is an $S$-module homomorphism that respects the group action. So $f: M \to N$ is $S\#G$-linear if and only if it is $S$-linear and $f(g(x))=g(f(x))$ for all $x \in M$, $g \in G$. 


We can define an $S\#G$-module structure on $\Hom_S(M,N)$: given $f: M \to N$ and $g \in G$, $(gf)(x)= g(f(g^{-1}(x)))$. It is routine to check that the action is compatible with the $S$-module structure. 


What is $\Hom_S(M,N)^G$? Well, $f$ is invariant if and only if $gf=f$ for all $g$ if and only if $(gf)(x)= f(x)$ for all $g$ if and only if $g(f(g^{-1}(x)))= f(x)$ for all $g$ if and only if $f(g^{-1}(x))= g^{-1}(f(x))$ for all $g$. So an $S$-linear map is invariant if and only if it is $S\#G$-linear. Another way of saying this is $\Hom_S(M,N)^G= \Hom_{S\#G}(M,N)$ (an actual equality). 


Fact: If $|G|$ is invertible in $S$, then taking $G$-invariants is an exact functor, i.e. if $0 \ma{} L \ma{\alpha} M \ma{\beta} N \ma{} 0$ is an exact sequence of $S\#G$-modules, then
	\[
	0 \ma{} L^G \ma{\text{res }\alpha} M^G \ma{\text{res }\beta} N^G \ma{} 0
	\]
is an exact sequence. 

Check: The restriction of an injective is clearly injective. Clearly the composition of the restrictions is also 0. We will only check surjectivity. Take $y \in N^G \subseteq N$. Then there is $x \in M$ with $\beta(x)=y$. Notice for any $g \in G$, $\beta(gx)=g(\beta x)=g(y)=y$. So 
	\[
	\beta \left(\dfrac{1}{|G|} \sum_{g \in G} g(x) \right)= y
	\]
and the sum is in $M^G$. The same trick works for exactness in the middle. 


Consequently, $\Ext_{S\#G}^i(M,N)= \Ext_S^i(M,N)^G$. 

\begin{cor}
An $S\#G$-module is projective if and only if it is projective over $S$. 
\end{cor}

\pf We know $P$ is projective over a ring $T$ if and only if $\Ext_T^i(P,-)=0$ for $i>0$. Then $_{S\#G}M$ is projective if and only if $\Ext_{S\#G}^i(M,-)=0$ for $i>0$ if and only if $\Ext_S^i(M,-)^G=0$. We know $\Ext_S^i(M,-)=0$ if and only if $_SM$ is projective. It remains to show that $\Ext_S^i(M,-)^G=0$ if and only if $\Ext_S^i(M,-)=0$. 

It is clear that if $\Ext_S^i(M,-)=0$ then $\Ext_S^i(M,-)^G=0$. Now if $M$ is projective, i.e. $\Ext_S^i(M,-)=0$, it is a direct summand of $(S\#G)^n$ for some $n$. But $S\#G$ is free as an $S$-module, so $M$ is also projective over $S$. \qed \\


\begin{cor}
If $S= k[x_1,\ldots,x_n]$, then $S\#G$ has global dimension $n$, i.e. $n= \max\{ \text{proj dim}_{S\#G} M \colon M \text{ f.g. over } S\#G\}$. 
\end{cor}

\pf Recall $\text{proj dim}_{S\#G} M= \max\{ i \colon \Ext_{S\#G}^i(M,-) \neq 0 \}$. But this is $\max \{ i \colon \Ext_S^i(M,-)^G \neq 0 \}$. But this is at most $\max \{ i \colon \Ext_S^i(M,-) \neq 0\}$, which is at most $n$ by Auslander-Buchsbaum-Serre, which says that the global dimension of a polynomial ring (or any regular ring) is $n$. So $\text{g, dim} S\#G \leq n$. To show equality, we must construct an $S\#G$-module of projective dimension $n$. The short version is that the Kozul Complex on $x_1,\ldots,x_n$ is an $S\#G$-linear free resolution of $S/(x_1,\ldots,x_n) \cong k$. 


The longer version: Let $V= (x_1,\ldots,x_n)/(x_1,\ldots,x_n)^2$. This is a $k$-vector space of rank $n$ with basis $x_1,\ldots,x_n$ (really bars). And $K_p:= S \otimes_k \bigwedge^p V$, where $p \geq 0$ and $\bigwedge^p V$ is the $p$th exterior power of $V$. This means it has basis $\{ x_{i_1} \extp x_{i_2} \extp \cdots \extp x_{i_p} \colon i_1<i_2<\cdots<i_p\}$. Then $S \otimes_k \bigwedge^p V$ is the free $S$-module on the same basis. Since $G$ acts on $S$ linearly, it acts on $V$. It therefore acts on $\bigwedge^p V$ for all $p$. The main thing about $\bigwedge^p V$ is $v \extp w= -(w \extp v)$ for all $v,w \in V$. With that, not only is each $\bigwedge^p$ a representation of $G$, the maps $\bigwedge^p V \to \bigwedge^{p+1} V$ given by $\omega \mapsto \omega \extp (\sum x_i)= \sum (\omega \extp x_i)$ and the maps are $G$-linear. The exact sequence 
	\[
	0 \ma{} S \otimes \bigwedge^0 V \ma{} S \otimes \bigwedge^1 V \ma{} S \otimes \bigwedge^2 V \ma{} \cdots \ma{} S \otimes \bigwedge^n V \ma{} 0
	\]
is an $S$-linear free resolution of $S/(x_1,\ldots,x_n)$. Note the last two above are congruent to $S^n \to S$ with map $e_i \mapsto \sum x_j$, $j \neq i$. Furthermore, each free module and each map (differential) is $G$-linear. So this is a free resolution of $k$ over $S\#G$. This can not be a shorter one since we know that $\text{proj dim}_S k= n$. So $\text{gl dim} S\#G= n$. \qed \\


So in the case where $S= k[W]$, the ring $S\#G$ encodes all $S$-modules with $G$-action, and has global dimension $n= \dim W$ (like $S$). 

The ``twist'' in the algebra structure is cooked up exactly to make a certain map a ring homomorphism. Let $S= k[W]$, $G$ a finite group with $|G| \in k^\times$, and $R= S^G$. Consider the endomorphism ring $\End_R(S)$ of $S$ as an $R$-module. Define
	\[
	\gamma: S\#G \ma{} \End_R(S)
	\]
by considering an $S$-linear combination of endomorphisms of $S$ as an endomorphism of $S$. 
	\[
	\sum s_g \cdot g \mapsto \sum s_g g.
	\]
Note: each $g \in G$, considered as an endomorphism of $S$, is $R$-linear
	\[
	g(rs)= g(r) g(s) = rg(s)
	\]
for $r \in R$, $s \in S$. Finally, $\gamma$ is a ring homomorphism. Moreover, $\gamma$ is not generally injective or surjective.


\begin{thm}[Auslander, 62]
If $G$ is small, then $\gamma$ is an isomorphism.
\end{thm}


To prove this, we will need Ramification Theory, i.e. unramified and \'etale maps. 



\subsection{Ramification Theory}

Recall a ring homomorphism $A \to B$, where $A,B$ are commutative noetherian rings, is of \emph{finite type} if $B$ is a finitely generated $A$-algebra, i.e. $B \cong A[x_1,\ldots,x_r]/I$ for some ideal $I$. The morphism is \emph{essentially of finite type} if $B$ is a localization of an $A$-algebra of finite type, i.e. $B \cong (A[x_1,\ldots,x_r]/I)_S$. 


\begin{dfn}[Ramified]
Let $\phi: (A,\fm,k) \to (B, \fn,l)$ is a local homomorphism ($\phi(\fm) \subseteq \fn$, i.e. no non-unites of $A$ become units in $B$) of local noetherian rings. We say $\phi$ is unramified if
\begin{enumerate}[(i)]
\item it is essentially of finite type
\item $\fm B= \fn$
\item $k \to l$ is a finite separable field extension
\end{enumerate}
If in addition $A \to B$ is flat, $\phi$ is called \'etale. 
\end{dfn}


\begin{rem}
Some people call this ``essentially unramified'' and reserve unramified for maps of finite type. Intuition if $p$ is a prime element in $\Z$ and $\mathcal{O}$ is some finite $\Z$-algebra, the prime $p$ might split, $qr=p$, or ramify, $q^e=p$. 
\end{rem}


\begin{ex}
1) A finite separable field extension is unramified and even \'etale. 

2) Any quotient $A \to A/I$, $I \neq 0$, is unramified (with no residue field growth) but never flat, so not \'etale. 

3) Let $(A,\fm,k)$ be a local ring, $f(x) \in A[x]$ a monic irreducible polynomial, and $q \subseteq A[x]$ a prime ideal containing $\fm$ not containing $f'(x)$. Set $B= (A[x]/(f(x)))_q$. What is $B/\fm B$? Well
	\[
	B \otimes_A A/\fm \cong (k[x]/(f(x)))_{\overline{q}}= k[x]/(f(x))
	\]
and in particular $f'(x) \neq 0$ in this ring (really its image). But then this is a finite separable extension of $k$. In particular, $\fm B$ must be a maximal ideal (following the congruences, get a field), so $\fm B= qB=\fn$ is the unique maximal ideal of $B$. So $B$ is unramified over $A$. This is also \'etale, though we will not show this. This construction is called a pointed \'etale neighborhood of $A$. 
\end{ex}


Facts: 
a) Every unramified local map $A \to B$ is `basically' of this form: every unramified local map $A \to B$ factors as a sequence of pointed \'etale neighborhood followed by a surjection. (``Local Structure Theorem for \'Etale Maps''). 

b) Taking $\varinjlim \{$ pointed \'etale neighborhoods of $A\}$ is ``the'' Henselization of $A$, the smallest $A$-algebra satisfying Hensel's Lemma $A \hookrightarrow A^n \hookrightarrow \widehat{A}$. 


Extended definition: A ring homomorphism $A \to B$ is unramified at a prime ideal $q$ in $\spec B$ if the induced map $A_{q \cap A} \to B_q$ is unramified. It is unramified if it is unramified at every prime ideal. 


\begin{ex}
If $l_1, \ldots, l_t$ are finite separable field extensions of a field $k$, then $k \to l_1 \times \cdots \times l_t$ is unramified (and in fact \'etale). 
\end{ex}


BIG FACT: Every unramified field extension of a field is of this form, products of finite separable extensions. (Serre, 50s?). 


Why is this truly a more general definition? Problem: For this to be consistent with the old definition, we need unramified-ness to localize. To do this, we need to give a different definition which is equivalent and obviously localizes. 


\begin{dfn}[Enveloping Algebra]
Let $A \to B$ be a ring homomorphism. The enveloping algebra is $B \otimes_A B$. 
\end{dfn}


BTW if $A$ and $B$ were noncommutative, what we would use is $B \otimes_A B^{\text{op}}$. There is a natural map $\mu: B \otimes_A B \to B$ given by $b \otimes b' \mapsto bb'$, extending by linearity. This is a surjective ring homomorphism. 


Set $J= \ker \mu$, an ideal of $B \otimes_A B$. Then $B \cong B \otimes_A B/J$. Equivalently, we have a short exact sequence
	\[
	0 \ma{} J \ma{} B \otimes_A B \ma{} B \ma{} 0.
	\]


Remarks: $J$ is generated (as an ideal of $B \otimes_A B$) by elements of the form $b \otimes 1 - 1 \otimes b$. Certainly, $J$ contains those. On the other hand if
	\[
	\mu \left( \sum_i b_i \otimes b_i' \right) = 0,
	\]
then $\sum_i b_i b_i' = 0$. But $\sum_i b_i b_i' = \sum_o (1 \otimes b_i')(b_i \otimes 1 - 1 \otimes b_i)$ is generated by elements of the appropriate `shape.' 


2) Caution: $B \otimes_A B$ has two $B$-module structures on the left and on the right: $b \cdot (b' \otimes b'')= bb' \otimes b''$, $(b' \otimes b'')b= b' \otimes b''b$ and \emph{they do not have to agree}. In particular, $J$ has two distinct $B$-module structures. Luckily, they coincide modulo $J^2$: Claim for any $b,b' \in B$
	\[
	b(b' \otimes 1- 1 \otimes b') - (b' \otimes 1 - 1 \otimes b')b \in J^2.
	\]
This is
	\[
	bb' \otimes 1 - b \otimes b' - b' \otimes b + 1 \otimes b'b= (b \otimes 1-1\otimes b)(b' \otimes 1 - 1 \otimes b') \in J^2
	\]
So $J/J^2$ has an unambiguous $B$-module structure. By the way, this is sometimes called the \emph{module of K\"ahler differentials} of $B/A$, written $\Omega^1_{B/A}$. 


3) If $A \to B$ is essentially of finite type, then $J/J^2$ is a finitely generated $B$-module. Specifically, if $B= (A[x_1,\ldots,x_r]/I)_W$, then $J/J^2$ is generated over $B$ by $\overline{x_i \otimes 1 - 1 \otimes x_i}$, $i=1,\ldots,r$> So $J/J^2$ localizes well: it vanishes if and only if it vanishes locally at every maximal or prime ideal. 


\begin{lem}
Let $A \to B$ be a ring homomorphism, essentially of finite type. TFTA:

i) $B$ is projective as a $B \otimes_A B$-module.
ii) the exact sequence
	\[
	0 \ma{} J \ma{} B \otimes_A B \ma{\mu} B \ma{} 0
	\]
splits as $B \otimes_A B$-modules. 

(iii) $\mu(\ann_{B \otimes_A B} J)= B$. 

iv) $J$ is generated by an idempotent of $B \otimes_A B$: a single element $e$ satisfying $e^2=e$

v) $J/J^2=0$.  
\end{lem}

\pf (i) $\iff$ (ii) is obvious. via the exact sequence. 

(ii) $\iff$ (iii): The map $\mu$ splits if and only if the induced homomorphism 
	\[
	\Hom_{B \otimes_A B}(B,\mu): \Hom_{B \otimes_A B} (B, B \otimes B) \ma{\mu \otimes -} \Hom_{B \otimes_A B}(B,B)
	\]
the identity is in the image, i.e. the map is surjective. We know $B \cong B \otimes_A B/J$ as $B \otimes_A B$-modules, so $\Hom_{B \otimes_A B}(B,X)= \Hom_{B \otimes_A B}(B \otimes_A B/J,X) \cong \{ x \in X \colon Jx=0 \} = \ann_X J$. So in those terms, we want
	\[
	\ann_{B \otimes_A B} J \ma{\mu} \ann_B J
	\]
to be surjective. So $\mu$ splits if and only if $\mu(\ann_{B \otimes_A B} J)= B$. 

Finally, (iv) $\iff$ (v) are true for any finitely generated ideals. 

(ii)  $\iff$ (iv): If $\mu: B \otimes_A B \to B$ splits, there is some $B \otimes_A B$-linear map $j: B \to B \otimes_A B$ with $\mu j= 1_B$. Set $e=j(1)$ (a separability idempotent). Then $e^2=e$ and $e$ generates (Check) $J$ as $B \otimes_A B$-ideal. \qed \\


\begin{prop}
Let $A \to B$ be essentially of finite type. TFAE:

i) the exact sequence 
	\[
	0 \ma{} J \ma{} B \otimes_A B \ma{\mu} B \ma{} 0
	\]
splits as $B \otimes_A B$-modules. 

ii) $A \to B$ is unramified

iii) $A_\fm \to B_\fn$ is unramified for every maximal ideal $\fn \subseteq B$ with $\fm= \fn \cap A$. 
\end{prop}

\pf In the notes. \qed \\


We shall try to explain what $\Omega_{B/A}= J/J^2$ has to do with (un)ramified-ness. The connection is derivations. 


\begin{dfn}[Derivation]
Let $A$ be a ring and $M$ an $A$-module. A function $D: A \to M$ is called a derivation if 
	\begin{itemize}
	\item $D(a+b)= D(a) + D(b)$
	\item $D(ab) = a D(b) + D(a) b$ (Leibniz/Product Rule)
	\end{itemize}
for all $a,b \in A$
\end{dfn}


Technically, this is a $\Z$-derivation. If $k \subseteq A$ is a subring so that $D$ is $k$-linear, i.e. $D(\alpha a)= \alpha D(a)$ for $\alpha \in k$, $a \in A$, then $D$ is called a $k$-derivation. 


\begin{rem} 
These behave like derivatives:
1) $D(1)=0$ 
2) $D$ is $k$-linear iff $D(k)= 0$, i.e. $D(\alpha)=0$ for all $\alpha \in k$. (Use product rule)
3) $D^{-1}(\{0\})$ is a subring of $A$, so there is a unique largest $k$ such that $D$ is $k$-linear. 
4) $D(a^n)= n a^{n-1} D(a)$ for any $a \in A$, $n \geq 0$. Simple to prove by induction. In particular, if $\char A= n$, then $D(a^n)= 0$ so $D$ is necessarily $A^n$-linear. Extending this, if $a \in A$ and $f(x) \in A[x]$, $D(f(a))= f'(a)D(a)$! 
5) If $\phi: M \to N$ is an $A$-module homomorphism and $D: A \to M$ is any derivation, then $\phi \circ D: A \to N$ is also a derivation. So if we write $\Der_k(A,M)= \{$k$\text{-linear derivations } A \to M\}$, then $\Der_k(A,M)$ is an $A$-module. [Take $\phi$ to be $M \ma{a} M$.] And in fact, $\Der_k(A,M)$ is a functor: any $\phi: M \to N$ induces a map $\Der_k(A,M) \to \Der_k(A,N)$ given by $\phi \mapsto \phi \circ$ and is an $A$-module homomorphism. 
\end{rem}


Is this functor representable, i.e. can it be written as a $\Hom$? Specifically, is there a ``special'' $A$-module $\Omega$ such that $\Der_k(A,M) \cong \Hom_A(\Omega,M)$ for every $M$? As it turns out, this is the case and we will construct this $\Omega$. 


\begin{ex}
Take $A= k[x]$. What is in $\Der_k(A,A)$? We know that $D(k)=0$ for all $k \in k$. If we know $D(x)$, then we are done as $D(f(x))= f'(x) D(x)$ for all $f$, so $D$ is determined by $D(x)$. In fact, $D(x)$ can be arbitrary. [Check the rules. Keeping in mind you have defined this on a generator.] If say $D(x)= q(x)$, then for any $f(x)$, $D(f(x))= f'(x) q(x)$. In other words, $D= q(x) \, \dfrac{d}{dx}$. Equivalently, $\Der_k(A,A) \cong A \, \dfrac{d}{dx}$ is a free $A$-module of rank 1, generated by $\dfrac{d}{dx}$. 
\end{ex}


\begin{ex}
$A= k[x_1,\ldots,x_n]$. Any function of the form $\sum_{i=1}^n q_i(x) \, \dfrac{\partial}{\partial x_i}$ is a derivation and these are in fact all the derivations. So $\Der_k(A,A)= \bigoplus_{i=1}^n A \, \dfrac{\partial}{\partial x_i}$ is a free module of rank $n$. 
\end{ex}


\begin{ex}
Take $A= k[x]$. What is in $\Der_k(A,M)$? We know that $D(k)=0$ for all $k \in k$. If we know $D(x)$, then we are done as $D(f(x))= f'(x) D(x)$ for all $f$, so $D$ is determined by $D(x)$. In fact, $D(x)$ can be arbitrary. [Check the rules. Keeping in mind you have defined this on a generator.] If say $D(x)= m$, then for any $f(x)$, $D(f(x))= f'(x) m$. In other words, $D= m \, \dfrac{d}{dx}$. Equivalently, $\Der_k(A,M) \cong M \, \dfrac{d}{dx}$ is a free $A$-module of rank 1, generated by $\dfrac{d}{dx}$. 
\end{ex}


Using these examples, we can see that for $A= k[x_1,\ldots,x_n]$, it should be the case that $\Omega{A/k}= A^n$. Now we actually construct $\Omega_{A/k}$. Now $\Omega_{A/k}$ should come with a universal derivation $d: A \to \Omega_{A/k}$ such that for any derivation $D: A \to M$, there is a unique $A$-module homomorphism $f: \Omega \to M$ making the following diagram commute
	\[
	\begin{tikzcd}
	A \arrow{rr}{d} \arrow[swap]{dr}{D} & & \Omega_{A/k} \arrow[dotted]{dl}{\exists! f} \\
	& M & 
	\end{tikzcd}
	\]
If such an object exists, it is unique by traditional abstract nonsense. It will turn out that $\Omega_{A/k} \cong J/J^2$, where $J= \ker(A \otimes_k A \ma{\mu} A)$. You can construct $\Omega_{A/k}$ abstractly. Let $F$ be the free $A$-module on symbols $\{ d_a \}_{a \in A}$. Let $H$ be the submodule generated by $\{d_{a+b} - d_A - d_b, d_{ab} - ad_b - bd_a, d_\alpha\}_{a,b \in A, \alpha \in k}$. Then $A \to F/H$ given by $a \mapsto d_a$ is the correct object. However, this definition is not useful. Is this even nonzero?! We focus on the fact that we shall have $\Omega_{A/k} \cong J/J^2$, and follow an alternative construction. 


Let $J = \ker(A \otimes_k A \to A)$. Then we know that $J/J^2$ is an $A$-module. Define $d: A \to J/J^2$ by $a \mapsto a \otimes_1 - 1 \otimes a$. Is this a derivation? The only real question here is does this satisfy the Leibniz rule?
	\[
	\begin{split}
	d(ab) &= ab \otimes 1 - 1 \otimes ab \\
	&= a(b\otimes 1 - 1\otimes b) + (a\otimes1 - 1\otimes a)b \\
	&= a d(b) + b d(a) \mod J^2
	\end{split} 
	\]


\begin{prop}
$(J/J^2,d)$ has the desired universal property. 
\end{prop}

\pf Let $D: A \to M$ be a derivation.
	\[
	\begin{tikzcd}
	A \arrow{rr}{d} \arrow[swap]{dr}{D} & & J/J^2 \arrow[dotted]{dl}{\exists! f} \\
	& M & 
	\end{tikzcd}
	\]
We use the ``idealization'' or ``trivial extension'' of $M$. The trivial extension is a ring $B= A \ltimes M= \left\{ \two{a}{m}{0}{a} \colon a \in A, m \in M \right\}$ under matrix multiplication. This is the same as $\{ (a,m) \colon A \oplus M \}$ with multiplication $(a,m)(a',m')= (aa',am'+a'm)$. Then $B$ is a ring, commutative if $A$ is commutative. We have $A \hookrightarrow B$ as $\{(a,0)\}_{a \in A}$ as a subring, and $M \hookrightarrow B$ as $\{(0,m)\}_{m \in M}$. Notice that $(a,0)(0,m)= (0,am')$ so $M$ is an ideal of $B$. Furthermore, $M^2=0$ by considering $(0,m)(0,m')$. There is a ring homomorphism $A \otimes_k A \to B= A \ltimes M$ given by $a \otimes a' \mapsto (aa', a'(Da))$. In particular, $h(a \otimes 1) = (a, D(a))$, $h(1 \otimes a) = (a,0)$. What happens to $J^2$? $h(a \otimes 1 - 1 \otimes a)= (a,D(a)) - (a,0)= (0,D(a)) \in M$. In particular, $J^2$ maps into $M^2=0$. So $h$ induces a homomorphism $J/J^2 \to M$ given by $a \otimes 1 - 1 \otimes a \mapsto D(a)$. This is exactly what is needed (along with $J^2 \to 0$) to make the diagram commute. \qed \\


\begin{prop}[Basic Properties of $\Omega_{A/k}$] \hfill
\begin{enumerate}[(i)]
\item if $A$ is generated as a $k$-algebra by elements $\{a_\lambda\}_{\lambda \in \Lambda}$, then $\Omega_{A/k}$ is generated by $\{ a_\lambda \otimes 1 - 1 \otimes a_\lambda\}_{\lambda \in \Lambda}= \{d(a_\lambda)\}_{\lambda \in \Lambda}$. 
\item if $A \cong k[\{x_\lambda\}_{\lambda \in \Lambda}]$ is a polynomial ring over $k$, then $\Omega_{A/k}$ is a free $A$-module on $\{d(x_\lambda) \}_{\lambda \in \Lambda}$. 
\item if $\{A_\lambda\}_{\lambda \in \Lambda}$ is a directed system of $k$-algebras, and $A = \varinjlim A_\lambda$, then $\Omega_{A/k} = \varinjlim \Omega_{A_\lambda/k}$. 
\item if $\phi: A \to A'$ is a ring homomorphism and $D: A' \to N$ is a derivation, then $D \circ \phi: A \to N$, so we obtain a map $\Der_k(A',N) \to \Der_k(A,N)$.
\item if $\phi: A \to A'$ is a ring homomorphism, there is an induced $A$-linear map $\Omega_{A/k} \to \Omega_{A'/k}$ given by $d(a) \mapsto d(\phi(a))$ and so an $A'$-linear map $A' \otimes_A \Omega_{A/k} \to \Omega_{A'/k}$. 
\end{enumerate}
\end{prop}


\pf \hfill

1) we have seen

3) do not care

4) is routine

2) We construct a $k$-derivation from $A \to \bigoplus A \, d(x_\lambda)$ and show that it has the universal property. We should send $x_\lambda$ to $d(x_\lambda)$. Extend this to monomials in the variables $x_\lambda$ using the Leibniz rule, and extend by additivity to all of $A$. In the end, this defines $\delta: A \to \bigoplus_{\lambda \in \Lambda} A \, d(x_\lambda)$ given by $f(\underline{x}) \mapsto \sum_\lambda \dfrac{\partial f}{\partial x_\lambda} \, d(x_\lambda)$. each polynomial involves only finitely many $\lambda$'s, so the sum is indeed finite. To show universality, let $D: A \to M$ be the derivation,
	\[
	\begin{tikzcd}
	A \arrow[swap]{dr}{D} \arrow{rr}{d} &  & \bigoplus A \, d(x_\lambda) \arrow[dotted]{dl}{f} \\
	& M & 
	\end{tikzcd}
	\]
We have to define $f(d(x_\lambda))= D(x_\lambda)$. This forms a well defined map since the $\{d(x_\lambda)\}$ form a basis. Commutativity and uniqueness are now also both obvious. 

5) Given $\phi: A \to A'$, we have 
	\[
	\begin{tikzcd}
	A \arrow{r}{d_A} \arrow{d}{\phi} & \Omega_{A/k} \arrow[dotted]{d} \\
	A' \arrow{r}{d_{A'}} & \Omega_{A'/k}
	\end{tikzcd}
	\]
By (4), the diagonal $d_{A'} \circ \phi: A \to \Omega_{A'/k}$ is a derivation. By the universal property of $\Omega_{A/k}$, there is a unique $A$-module homomorphism $\Omega_{A/k} \to \Omega_{A'/k}$ making the diagram commute. The last assertion that this induces an $A' \otimes_A \Omega_{A/k} \to \Omega_{A'/k}$ is just a general fact about tensor products. \qed \\



Let $A \to B$ be a map.

\begin{prop} \label{prop:omegabspan}
Let $B$ be an $A$-algebra and $I \subseteq B$ an ideal. Then $\Omega_{(B/I)/A} \cong \Omega_{B/A}/K$, where $K$ is the $B$-span of $\{d(i)\}_{i \in I}$. 
\end{prop}

\pf First, for any $b \in B$ and $i \in I$, $id(b)= d(bi) - bd(i)$, which are both in $K$. Therefore, $I \Omega_{B/A} \subseteq K$ since $B$ is generated by $\{d(b)\}_{b \in B}$. But then $\Omega_{B/A}/K$ is a $B/I$-module. To check the universal property, observe we have an induced derivation $\overline{d}: B/I \to \Omega_{B/A}/I$ given by $\overline{b} \mapsto \overline{d(b)}$, which is well defined by the work above. Suppose then that $D: B/I \to M$ is any $A$-linear derivation. 
	\[
	\begin{tikzcd}
	B \arrow[swap]{dr}{\pi} \arrow{rr}{d} & & \Omega_{B/A} \arrow[dotted]{dd}{f} \\
	&  B/I \arrow[swap]{dr}{D} & \\
	 & & M
	\end{tikzcd}
	\]
We know $D \circ \pi$ is still a derivation, so there exists a unique $f: \Omega_{B/A} \to M$ such that $f \circ d= D \circ \pi$. Then $f(d(i))= D(\pi(i))= 0$so $f$ maps $K$ to zero. Therefore, we have an induced map $\Omega_{B/A}/K \ma{\overline{f}} M$ which is clearly unique. \qed \\



\begin{prop}
Let $k$ be a field and $p(x) \in k[x]$ be an irreducible polynomial, i.e. $A= k[x]/(p(x))$ is a field. Then $\Omega_{A/k} \cong A/(p'(x))= k[x]/(p(x),p'(x))$. In particular, $\Omega_{A/k}=0$ if and only if $k \to A$ is separable, i.e. unramified. 
\end{prop}

\pf The last sentence follows from the first as the extension is separable if and only if $\gcd(p,p')=1$ if and only if $(p,p')= k[x]$. Set $S= k[x]$. We know that $\Omega_{S/k} \cong S \, \dfrac{d}{dx}$. Using Proposition~\ref{prop:omegabspan}, we have
	\[
	\Omega_{A/k} \cong \Omega_{S/k} / S\text{-span of }\{d(i)\}_{i \in (p)}.
	\]
However, elements in $(p)$ are of the form $gp$ for some $g \in k[x]$. Then $d(gp)= gd(p) + pd(g)= gp'd(x) + pg'd(x) \in S\text{-span of }p'd(x) \text{ and }pd(x)$. On the other hand, $p'd(x)=d(p) \in \{d(i)\}$, and $pd(x)= d(px) - xd(p) \in S\text{-span of } \{d(i)\}$. Therefore, the $S$-span of $\{d(i)\}$ is the submodule of $S \, dx$ generated by $p' dx$ and $p dx$. Hence,
	\[
	\Omega_{A/k} \cong S\,dx / S(p'\,dx,p\,dx) \cong S/(p,p').
	\]
\qed \\


\begin{rem}
The proof that $A \to B$ is unramified if and only if $\Omega_{B/A}=0$ proceeds by reducing to the case where $A$ is a field, then using direct limits to reduce to the case of finite type, then (more work in this step) reducing to the case where $B$ is a simple field extension of $A$, which is the case we just completed. 
\end{rem}


\begin{rem}
If $A= k[x_1,\ldots,x_n]/(p_1,\ldots,p_r)$, then $\Omega_{A/k} \cong A^n/\im J$, where $J$ is the Jacobian matrix
	\[
	J_{n \times r}:= \left( \dfrac{\partial P_j}{\partial x_i} \right)_{i,j}
	\]
\end{rem}



Recall that we were trying to prove 

\begin{thm}[Auslander, 1962]
Let $S= k[x_1,\ldots,x_n]$, $G \subseteq \GL_n(k)$ such that $|G| \in k^\times$, and $R= S^G$. If $R \to S$ is unramified in codimension 1, then $\gamma: S\#G \to \End_R(S)$ is an isomorphism (here unramified in codimension 1 means unramified when localized at any height 1 prime of $S$):
	\[
	R_{q \cap R} \to S_q
	\] 
is unramified at every height 1 $q \in \spec S$. Equivalently, $(\Omega_{S/R})_q=0$. 
\end{thm}

\pf As a first step, we reduce to the case of dimension 1. Recall from an old Lemma that if $A$ is a noetherian commutative ring and $M \ma{f} N$ is a $A$-homomorphism with $M$ satisfying $(S_2)$ and $N$ satisfying $(S_1)$, then $f$ is an isomorphism if and only if $f_p$ is an isomorphism for every height 1 $p \in \spec A$. In our situation, $M= S\#G$ is free over $S$, hence $(S_2)$. Then $N= \End_R(S)$ must also have depth 2 by an old lemma. So to show $\gamma$ is an isomorphism to show $\gamma_q$ is an isomorphism for every height 1 $q \in \spec S$. So from now on we assume $R \to S$ is unramified. 


As a second step, it is enough to show that $\gamma$ is a split surjection. Both source and target are torsion-free $S$-modules and have ranks 
	\[
	\rank (S\#G) = \rank_R( \bigoplus_{g \in G} S) = \rank_R(S) |G| = |G|^2.
	\] 
On other hand, $\rank_R(\End_R(S))= \rank_R(\Hom_R(S,S))= (\rank_R(S))^2= |G|^2$. Any split surjection between them is an isomorphism. The remainder of the proof constructs a splitting as in this diagram
	\[
	\begin{tikzcd}
	S\#G \arrow{r}{\gamma} & \End_R(S) \arrow{d}{f \mapsto f \otimes \hat{\rho}} \\
	S \otimes_R (S\#G) \arrow{u}{\tilde{\mu}} & \Hom_S(S \otimes_R S, S \otimes_R (S\#G)) \arrow{l}{\text{ev}_\epsilon}
	\end{tikzcd}
	\]
where going around the square yields the identity. 

Step 3: Right map: We already know that $S \hookrightarrow S\#G$ by sending $s \in S$ to $s \cdot 1_G$. It also sits inside via a ``Reynold's type'' map $\hat{\rho}: S \to S\#G$ via $s \mapsto \dfrac{1}{|G|} \sum_{g \in G} g(s) \cdot g$. It is routine to check that $\hat{\rho}$ is an injective ring homomorphism, and $\hat{\rho}(1)= \dfrac{1}{|G|} \sum_{g \in G} g$ is an idempotent of $S\#G$. The image of $\hat{\rho}$ is the set of fixed points $(S\#G)^G$ and $(\gamma \circ \hat{\rho})(1)$ is the Reynolds operator $\rho: S \to S$. Tensoring with $\hat{\rho}$ over $R$ sends $f: S \to S$ to $f \otimes \hat{\rho}: S \otimes_R S \to S \otimes_R (S\#G)$. 


Step 4: $\tilde{\mu}$. We use the assumption that $R \to S$ is unramified. Equivalently, the short exact sequence of $S \otimes_R S$-modules 
	\[
	0 \ma{} J \ma{} S \otimes_R S \ma{\mu} S \ma{} 0
	\]
splits. As $S$-modules, this is trivial. As $R$-modules, tensoring with $S$ on the right by $S\#G$
	\[
	0 \ma{} J \otimes_S (S\#G) \ma{} S \otimes_R S \otimes_S (S\#G) \ma{\tilde \mu} S \otimes_S  (S\#G) \ma{} 0.
	\]
This is
	\[
	0 \ma{} J \otimes_S (S\#G) \ma{} S \otimes_R (S\#G) \ma{\tilde{\mu}} S\#G \ma{} 0.
	\]
This stays exact since the other one was split. By the way, it is important to use the \emph{left} $S$-module structure in this sequence (the left was `used up'). The map $\tilde{\mu}$ is $t \otimes (s \cdot g) \mapsto ts \cdot g$. 


Step 5: $\epsilon$. We will construct a certain element $\epsilon \in S \otimes_R S$ and evaluate homomorphisms at $\epsilon$. 

Back to 
	\[
	0 \ma{} J \ma{} S \otimes_R S \ma{\mu} S \ma{} 0
	\]
Let $j: S \to S \otimes_R S$ be a splitting for $\mu$, so $j$ is $S \otimes_R S$-linear and $\mu \circ j= 1 \, ids$. Set $\epsilon= j(1)$. Then of course, $\mu(\epsilon)=1$. Furthermore, $\epsilon$ kills $J$, i.e. $\epsilon(s \otimes 1 - 1 \otimes s)=0$ for every $s \in S$. 


Step 6: A short computation: Write $\epsilon = \sum x_i \otimes y_i$ for $x_i,y_i \in S$. We claim that for any $g \in G$, 
	\[
	\sum x_i g(y_i) = 
	\begin{cases}
	1, & g= 1_G \\
	0, &  \text{otherwise}
	\end{cases}
	\]
To see this, if $g= 1_G$, then the left hand side is $\sum x_i y_i = \mu(\epsilon)=1$. Also for any $s \in S$,
	\[
	(s \otimes 1)( \sum x_i \otimes y_i) = (\sum x_i \otimes y_i)(1 \otimes s)
	\]
Otherwise,  if and only if $\sum s x_i \otimes y_i= \sum x_i \otimes sy_i$. Apply $1 \otimes g$ to both sides
	\[
	\sum sx_i \otimes g(y_i) = \sum x_i \otimes g(s) g(y_i)
	\]
Collapse the $\otimes$ with $\mu$ 
	\[
	s \sum x_i g(y_i) = g(s) \sum x_i g(y_i)
	\]
If $g \neq 1$, then there is some $s$ with $g(s) \neq s$. So $\sum x_i g(y_i)= 0$. 


Step 7: A bigger computation: Start with $f \in \End_R(S)$. 
	\[
	\begin{split}
	\gamma(\tilde{\mu}(\text{ev}_\epsilon(f \otimes \hat{\rho})))(s)&= \gamma(\tilde{\mu}( (f \otimes \hat{\rho})(\epsilon)))(s) \\
	&= \gamma(\tilde{\mu}( (f \otimes \hat{\rho})( \sum_i x_i \otimes y_i)))(s) \\
	&= \gamma(\tilde{\mu}( \sum_i f(x_i) \otimes \hat{\rho}(y_i)))(s) \\
	&= \gamma( \sum_i f(x_i) \hat{\rho}(y_i))(s) \\
	&= \gamma( \sum_i f(x_i) (\dfrac{1}{|G|} \sum_{g \in G} g(y_i) g))(s) \\
	&= \dfrac{1}{|G|} \sum f(x_i) \underbrace{\sum_{g \in G} g(y_i) g(s)}_{\text{fixed by every grp elmnt in }R \text{ is }R\text{-lin}} \\
	&= \dfrac{1}{|G|} f \left( \sum_i \sum_g x_i g(y_i) g(s) \right) \\
	&= \dfrac{1}{|G|} f \left( \sum_g \left( \sum_i x_i g(y_i) \right)  g(s) \right) \\
	&\stackrel{*}{=} \dfrac{1}{|G|} f \left( \left( \underbrace{\sum x_i y_i}_{=1} \right) s \right) \\
	&= \dfrac{1}{|G|} f(s)
	\end{split}
	\]
since only term which survives is where $g=1$. Then the whole composition is multiplication by $1/|G|$. Rescale to get the identity so $\gamma$ is a split surjection. \qed \\


%%%%%%%%%%%%%%%


We saw if the extension $R=S^G \hookrightarrow S=k[x_1,\ldots,x_n]$ is unramified in codimension 1, then the ring map $\gamma: S\#G \to \End_R(S)$ is an isomorphism. 

When is that extension unramified in codimension 1? Well, when $G$ is small! That is, contains no pseudo reflections. Intuitively, suppose $V \subseteq k$ is a codimension 1 subspace. Then $V+ \ker f$ for some linear form $f \in k[x_1,\ldots,x_n]$. The ideal $(f) \subseteq k[x_1,\ldots,x_n]$ is a height-one prime, and the extension is ramified at that prime if and only if $W$ is the fixed hyperplane of a pseudo-reflection. The theorem is


\begin{thm}[Auslander, 1962]
The extension $R= S^G \hookrightarrow S$ is unramified in codimension 1 if and only if $G$ is small. 
\end{thm}

\pfsk (Details in the notes) (There is a lot of classical background, i.e. before one went to graduate school). If $q \subseteq S$ is a height-one prime, $\fp=q \cap R$ is again a height 1 (going up/down) so $R_\fp \hookrightarrow S_q$ is a finite extension of 1-dimensional local rings. Both are regular so are discrete valuation rings (only ideals are $\fp^n$ and $q^n$). SO $\fp S_q= q^e S_q$ for some $e$, called the ramification index. On the other hand, $R_\fp/\fp R_\fp \hookrightarrow S_q/ qS_q$ is a field extension of degree, say $f$, called the inertia degree. [Unramified means $e=1$.] Define $D(q)=\{ g \in G \colon g(q)=q \}$ decomposition group of $q$. Define $T(q)= \{ g \in G \colon g(s)-s \in q \forall s \in S\}$ the inertia group of $q$. Then $T(q) \subseteq D(q)$. One then shows $T(q) \neq \{1\}$ then $q=(s)$ for some linear $s \in S$. Now if $W$ is the zero set of $s$, a codimension-1 subspace of $k^n$, every element of $T(q)$ fixes $W$, so is a pseudo-reflection. \qed \\


Being the same paper as the result from above. By the way, the same techniques allow us to characterize when $R$ is an isolated singularity, i.e. $R_p$ is a regular local ring for every non-maximal prime $p$. For each $g \in G$, set $U_g:= (I_n-g)k^n \subseteq k^n$. By rank-nullity, $\dim U_g= \rank(I-g)= n - \dim \ker(I-g)= n- \text{mult. of 1 as eigenvalue of }g$.  Recall $g$ is diagonalizable since it has finite order so it is contained in a group of finite order its characteristic polynomial has distinct roots. So $g$ is a pseudo-reflection if and only if multiplicity of 1 is $n-1$ if and only if $\dim U_g = 1$. Set $I= \bigcap_{g \in G \setminus\{1\}} (U_gS \cap R)$. Then $T(q)= \{1\}$ ($T(q)= \{ g \colon g(s)-s \in q\}$) if and only if $q$ does not contain $\cap_{g \neq 1} U_gS$. If $g(s)-s \in q$ for all $s$, $(I-g)(s) \in q$, $U_g \subseteq q$, $U_gS \subseteq q$. So one can show $R_\fp$ is regular if and only if $T(q)=\{1\}$ if and only if $q \not\supseteq \cap_{g \neq 1} U_gS$ if and only if $\fp \not\subseteq I$. So $R$ is an isolated singularity if and only if the only prime ideal of $R$ that contains $I$ is its maximal ideal. So the following are equivalent:
	\begin{itemize}
	\item $R$ is an isolated singularity
	\item $U_g= k^n$ for every $g \neq 1$
	\item no $g \neq 1$ has 1 for an eigenvalue
	\end{itemize}
Note if $n= 2$, this is equivalent to being small. If $n \geq 3$, this is stronger. Back to $\gamma: S\#G \to \End_R(S)$. 


What was the point of this result, i.e. the map being an isomorphism? Recall the direct summand of an $A$-module $M$ are in one-to-one correspondence with idempotents $e \in \End_A(M)$: $N/M$ corresponds to $(\text{proj}_N)^2= (\text{proj}N)$ while $e^2=e$ corresponds to $(\im e)$. 


\begin{cor}
Assume $G$ is small. Then we have ring isomorphisms 
	\[
	\begin{tikzcd}
	S\#G \arrow{r}{\iota} \arrow[dotted,swap]{rrd}{\gamma} & (S\#G)^{\text{op}} \arrow{r}{\nu} & \End_{S\#R}(S\#G) \arrow{d}{\text{res}} \\
	& & \End_R S
	\end{tikzcd}
	\]
defined by $\iota(s \cdot g)= g^{-1}(s) \cdot g^{-1}$ (trivial), $\nu(s \cdot g)(t \cdot h)= (t \cdot h)(s \cdot g)$ (right multiplication) (general result), res is the restriction of $f: S\#G \to S\#G$ to the subring $S= (S\#G)^G= \hat{\rho}(S)$ (crux). The composition is the $\cong$ $\gamma$. So we get bijections between (simple chase):
	\begin{itemize}
	\item the $R$-direct summands of $S$
	\item the $S\#G$-direct summand of $S\#G$
	\item (the indecomposable projective $S\#G$)(don't know this yet)
	\end{itemize}
Explicitly, if $P_1,\ldots,P_r$ are the indecomposable direct summand of $S\#G$ as a module over itself, then $P_1^G, \ldots, P_r^G$ are the indecomposable $R$-direct summands of $S$. 
\end{cor}


So to understand $\add_R(S)$, we just have to understand $\add_{S\#G}(S\#G)$, and these are precisely the projective $S\#G$-modules (free $S$-modules with $G$-action by Serre's Theorem). To classify the projective $S\#G$-modules, we go back to the representations


\begin{rem}
Let $M$ be an $S\#G$-module, and $W$ a finite dimensional representation of $G$. Then $M \otimes_k W$ is an $S\#G$-module. Also, $M \otimes_k W \cong M \otimes_k k^r \cong M^r$ as $S$-modules, and $G$ acts diagonally $g(m \otimes \alpha)= g(m) \otimes g(\alpha)$. We have a functor $\mathcal{F}: \text{rep-}G \to S\#G\text{-module}, \text{ free over }S$, i.e. projective $S\#G$-modules, given by $W \mapsto S \otimes_k W$. Also, $\mathcal{G}: \text{proj }S\#G\text{-module} \to \text{rep-}G$ given by $P \mapsto P/(x_1,\ldots,x_n)P$. 
\end{rem}


\begin{ex}
$G= B\mathbb{D}_2 \cong Q_8$, of order 8. 
	\[
	G= \left\{ \two{\pm 1}{}{}{\pm 1}, \two{}{\pm i}{\pm i}{}, \two{}{\mp 1}{\pm 1}{}, \two{\pm i}{}{}{\mp i} \right\} \subseteq \SL_2(\C)
	\]
generated by $B= \two{i}{}{}{-i}$, $A= \two{}{i}{i}{}$ ($B^2=A^2=ABAB= -I$). We know the representation theory of $G$. There are 4 1-dimensional representations, $\beta_{++}, \beta_{+-}, \beta_{-+}, \beta_{--}$, which take $(A,B)$ to $(\pm 1, \pm 1)$. Also, the given representation $G \subseteq \SL_2(\C)$ is 2-dimensional. Let's consider the $k[u,v]\#G$-module $k[u,v] \otimes_k \rho$. This is isomorphic as $k[u,v]$-module to $k[u,v] \oplus k[u,v]$, since $\rho$ is a 2-dimensional vector space. How does $A$ act on it? ($Au=iv$ and $Av=iu$)
	\[
	A \cdot \left( f(u,v) \otimes \begin{pmatrix} \alpha \\ \beta \end{pmatrix} \right) = A \cdot f(u,v) \otimes A \begin{pmatrix} \alpha \\ \beta \end{pmatrix}= f(iv,iu) \otimes \begin{pmatrix} i\beta \\ i\alpha \end{pmatrix}
	\]
As $S$-modules, the isomorphism between $k[u,v] \otimes_k \rho \to k[u,v]^2$ is just $f \otimes \begin{pmatrix} \alpha \\ \beta \end{pmatrix} \mapsto \begin{pmatrix} \alpha f  \\ \beta f \end{pmatrix}$. If we write elements of $k[u,v] \otimes \rho$ as vectors $\begin{pmatrix} f \\ g \end{pmatrix}$, how does $A$ act? 
	\[
	A \begin{pmatrix} f \\ g \end{pmatrix} = \begin{pmatrix} Aig \\ Aif \end{pmatrix}= \begin{pmatrix} ig(iv,iu) \\ if(iv,iu) \end{pmatrix}.
	\]
\end{ex}


\begin{prop}
These operations are inverse to each other on objects (see remark). In other words, $\mathcal{G} \mathcal{F}(W)= S\otimes_k W/(x_1,\ldots,x_n) S \otimes_k W \cong W$ and $\mathcal{F} \mathcal{G}(P)= S \otimes_k P/(x_1,\ldots,x_n)P \cong P$. In particular, these define a bijection between irreducible representations of $G$ and indecomposable projective $S\#G$-modules. 
\end{prop}







\begin{rem}
$\mathcal{F}$ and $\mathcal{G}$ do not define an equivalence of categories or even an adjount pair, adjointness would be $\Hom_{kG}(\mathcal{G}(P),U) = \Hom_{S\#G}(P,\mathcal{F}(U))$ but the LHS is a finite dimensional vector space, while the RHS is a free $S$-module. 
\end{rem}







%%%%%%%%%%%%%%%%%

Recall if $M$ is an $S\#G$-module and $W$ is a representation of $G$, then $M \otimes_k W$ (with the diagonal action of $G$) is again an $S\#G$-module. In the special case where $M=S$< we have $S \otimes_k M$. We can take $G$-invariants (of any $S\#G$-module) to get $(S \otimes_k W)^G$. Call this the \emph{module of covariants} of $W$. It is an $R$-module ($R=S^G$). Define functors $\mathcal{F}: \text{ rep G} \to \text{proj }S\#G$ via $W \mapsto S \otimes_k W$ and $\mathcal{G}: \text{ proj }S\#G \to \text{ rep }G$ given by $P \mapsto P/(x_1,\ldots,x_n)P$. 


In particular, we get a corollary,

\begin{cor}
Let $V_1,\ldots,V_d$ be a complete list of representatives for the irreducible representations of $G$, then $S \otimes_k V, \ldots, S \otimes_k V_d$ is a complete list of representatives for the projective $S\#G$-modules. 
\end{cor}


In particular (by Maschke's Theorem) every finitely generated projective $S\#G$-module is uniquely a direct sum of those. And finally, we also have

\begin{cor}
Taking invariants of finitely generated projective $S\#G$-modules gives bijections between indecomposable projective $S\#G$-modules with indecomposable $R$-summands of $S$ and irreducible representations of $G$, given by $W \leftrightarrow S \otimes_k W \leftrightarrow (S \otimes_k W)^G$. In particular, if $V_1,\ldots,V_d$ are a complete set of representatives for the irreducible representations of $G$, then $(S \otimes_k V_1)^G, \ldots, (S \otimes_k V_d)^G$ form a complete set of representatives for the indecomposable $R$-direct summands of $S$. 
\end{cor}


Next goal is to work out an example. But first, we shall need a few lemmas. What is the relation between $R_\rho$ (the isotypic component of $\rho$ in $S$) and the module of covariants $(S \otimes_k \rho)^G$? Recall if $V$ is an irreducible representation of $G$ and $W$ is any representation, the isotypic component of $V$ in $W$ is the direct sum of all summands of $W$ isomorphic to $V$. Equivalently, it is the image of the map $\Hom_G(V,W) \otimes_k V \to W$ given by $f \otimes v \mapsto f(v)$. This is because if $W \cong V^a \oplus V'$, where $V'$ has no summand isomorphic to $V$, then $\Hom_G(V,V')=0$, and the map above sends 
	\[
	\begin{tikzcd}
	\underbrace{\Hom_G(V,V^a) \otimes V}_{} \arrow[draw=none]{d}{\relsize{2}{\rotatebox[origin=c]{90}{$=$}}} \arrow{r} & W \\
	\End(V)^a \otimes V \arrow{r} & W
	\end{tikzcd}
	\]
and the $i$th standard basis vector of $\End(V)^a$ maps isomorphically onto the $i$th summand of $V$ in $W$. We can take $W=S$, the polynomial ring. SO the isotypic component of a map $\rho$ in $S$ is the image of $\Hom_G(\rho,S) \otimes \rho \to S$. Recall, $\Hom_G(\rho,S) = \Hom_k(\rho,S)^G$ and furthermore for any vector spaces $A,B$, $\Hom_k(A,B) \cong B \otimes_k A^*$ via the map $b \otimes \lambda \mapsto (a \mapsto \lambda(a)b)$. So the isotypic component $R_\rho \cong \Hom_G(\rho,S) \otimes \rho \cong \Hom_k(\rho,S)^G \otimes \rho \cong (S \otimes_k \rho^*)^G \otimes \rho$. So $R_\rho$ ``comes from'' the module of covariants for the dual representation $\rho^*$. Meaning, since $\rho$ is just a vector space of dimension $\dim \rho$,
	\[
	R_\rho \cong ( (S \otimes_k \rho^*)^G )^{\dim \rho}.
	\]
$\rho^*$, the dual representation, is defined as follows: if $\rho: G \to \GL(V)$, then $\rho^*: G \to \GL(V^*)$ given by $g \mapsto [\rho(g)^{-1}]^T$. In particular, if $\rho$ is a unitary representation, i.e. its image lies in the unitary group, so that $\rho(g)^{-1}= \rho(g)^*$, complex conjugate transpose, then the dual representation $\rho^*$ sends $g \in G$ to $[\rho(g)^{-1}]^T= [\overline{\rho(g)}^T]^T= \overline{\rho(g)}$. So $\rho^*$ is just the complex conjugate of $\rho$. 



Now the example (the smallest nonabelian example). 


\begin{ex}
Consider $G= B\mathbb{D}_2 \cong Q_8$ given by 
	\[
	G= \left\{ \pm \two{1}{}{}{1}, \pm \two{i}{}{}{-i}, \pm \two{}{-1}{1}{}, \pm \two{}{i}{i}{} \right\}.
	\]
Note $G \subseteq \SU(2)$. Furthermore, $G$ is generated by $A= \two{}{i}{i}{}$ and $B= \two{i}{}{}{-i}$. Then $-I= A^2= B^2= (AB)^2$. In particular, $A,B, AB$ have order 4. Furthermore, $G$ has the presentation $\langle i,j,k \;|\; i^2=j^2=(ij)^2, i^4=1 \rangle$. What are the conjugacy classes? The conjugacy classes are $\{I\}, \{-I\}, \{A,-A\}, \{B,-B\}, \{AB,-AB\}$ (noting $A^3= -A$). In particular, we know the character table. There are four 1-dimensional representations $G \to k^\times$ sending $A$ and $B$ to $\pm 1$ and one 2-dimensional irreducible representation, $\rho: G \hookrightarrow \GL_2(\C)$. The character table is then
	\begin{table}[htb]
	\centering
	\begin{tabular}{l|rrrrr}
	$B\mathbb{D}_2$ &  $[I]$ & $[-I]$ & $[A]$ & $[B]$ & $[AB]$ \\ \hline
	$\beta_{++}$ (triv) & 1 & 1 & 1  & 1 & 1 \\
	$\beta_{+-}$ & 1 & 1 & 1 & $-1$ & $-1$ \\
	$\beta_{-+}$ & 1 & 1 & $-1$ & 1 & $-1$ \\
	$\beta_{--}$ & 1 & 1 & $-1$ & $-1$ & 1 \\
	$\rho$ & 2 & $-2$ & 0 & 0 & 0 
	\end{tabular}
	\end{table}
How do $A$ and $B$ act on $S= k[u,v]$? $Au= iv$ and $Av= iu$, $Bu = iu$ and $Bv= -iv$. We previously computed the invariant ring $R= S^G= (S \otimes_k \text{triv})^G= (S \otimes_k \overline{\text{triv}})^G$ by computing the Molien series 
	\[
	M_G(t)= \dfrac{1}{|G|} \sum_{g \in G} \dfrac{1}{\det(I-tg)}= \dfrac{1+t^6}{(1-t^2)^2}= 1 + 2t^4 + t^6 + 3t^8 + 2t^{10} + \cdots
	\]
and found generators $x= u^4+v^4$, $y= u^2v^2$, $z= uv(u^4-v^4)$. This showed that $R \cong k[X,Y,Z]/(X^2Y-4Y^3-Z^2)$. Now we have $\overline{\beta_{+-}}= \beta_{+-}$ since its values are real and $S \otimes_k \beta_{+-}= S \otimes_k k \cong S$, ignoring the $G$-structure, but the $G$-action is diagonal $A(f \otimes \alpha)= Af \otimes \overline{\beta_{+-}(A)} \alpha= Af \otimes \alpha$ and $B(f \otimes \alpha)= Bf \otimes \overline{\beta_{+-}(B)} \alpha= Bf \otimes (-\alpha)= -Bf \otimes \alpha$. Under the identification, $S \otimes \overline{\beta_{+-}}= S$, this gives $Af= A(f)$ and $Bf= -B(f)$. This can also be expressed as $(Af)(u,v)= f(iv,iu)$ and $(Bf)(u,v)= -f(iu,-iv)$. So we are searching for polynomials $f(u,v)$ such that $f(iv,iu)= f(u,v)= -f(iu,-iv)$. The Molien series is 
	\[
	M_{\beta_{+-}}= \dfrac{1}{|G|} \sum_{g \in G} \dfrac{\beta_{+-}(g)}{\det(I-tg)}= \dfrac{t^2}{(t^2-1)(t^2+1)}= t^2 + t^4 + 2t^6 + \cdots
	\]
So we need \emph{at least} one quadratic and one quartic (the ones of degree 6 \emph{might} be $R$-multiples of the one of degree 2). Note in particular we are looking for polynomials invariant under the $A$-action, and $A$ generates a cyclic group of order 4: $Au \mapsto iv$, $Av \mapsto iu$. A change of variables $A(u+v)= i(u+v)$, $A(u-v)= iv - iu= -i(u-v)$. So $k[u,v]^A= k[(u+v)^4, (u+v)(u-v), (u-v)^4]$. So now we want to find $f \in k[(u+v)^4, u^2-v^2,(u-v)^4]$ so that $-f(iu,-iv)= f(u,v)$. Then $B(u^2-v^2)= (iu)^2 - (-iv)^2= -u^2 + v^2$ so $u^2-v^2$ is in the module of covariants
	\[
	\begin{split}
	B((u+v)^4)&= (iu-iv)^4= (u-v)^4 \\
	B((u-v)^4)&= (iu+iv)^4= (u+v)^4
	\end{split}
	\]
So $B((u+v)^4-(u-v)^4)= -((u+v)^4-(u-v)^4)$, and $(u+v)^4-(u-v)^4= 8(u^3v+uv^3)$. So $R_{\beta_{+-}}= R(u^2-v^2) + R(u^3v+uv^3)$. One has to check that $X(u^2-v^2)$ and $Y(u^2-v^2)$ are linearly independent elements of degree 6, so there are not any new generators in degree 6. The same thing holds in degree 8. By Noether's Theorem, we do not need any generators in degrees greater than $|G|= 8$. Therefore, we have computed $R_{++}= R= k[u,v]^G= k[u^4+v^4, u^2v^2, uv(u^4-v^4)]$ and $R_{+-}= R(u^2-v^2)+R(u^3v+uv^3)$. For $\beta_{-+}$, we want to find $f \in S$ such that $-Af= f= Bf$. The Molien series is the same:
	\[
	\dfrac{t^2}{(t^2-1)^2(t^2+1)}= t^2 + t^4 + 2t^6 + \cdots,
	\]
so again we look in degrees 2 and 4. Since we want $f$ to be $B$ invariant, we use the fact that we know $k[u,v]^B= k[u^4,uv,v^4]$. Furthermore, $A\cdot uv= (iv)(iu)= -uv$. Then $Au^4= (iv)^4= v^4$, $Av^4= (iu)^4= u^4$. Therefore, $A(u^4-v^4)= -(u^4-v^4)$, showing that $R_{-+}= R(uv) + R(u^4-v^4)$. For $\beta_{--}$, we have the same Molien series and the same procedures show that $R_{--}= R(u^2+v^2) + R(u^3v-uv^3)$. 

We now consider $\rho$, the given representation. We can again, since we know the matrices involved, compute the Molien series 
	\[
	M_\rho(t)= \dfrac{1}{8} \sum_{g \in G} \dfrac{\text{tr}(\overline{\rho(g)})}{\det(I-tg)}= \dfrac{t}{(1-t^2)^2}= t+ 2t^3 + 3t^5 + 4t^7 + \cdots.
	\]
Notice we have accounted for Hilbert series $M_G(t)+ 3M_{+-}(t) + M_\rho(t)$. The Hilbert series of $S= k[u,v]$ is $\dfrac{1}{(1-t)^2}$. But
	\[
	\dfrac{1}{(1-t)^2} - M_G(t) - 3 M_{+-}(t)= \dfrac{2t}{(1-t^2)^2}.
	\]
So there are 2 ($=\dim \rho$) copies of $(S \otimes_k \rho^*)^G$ in $S$. The action of $G$ on $S \otimes_k \rho^*$ is 
	\[
	A \left( f \otimes \begin{pmatrix} \alpha \\ \beta \end{pmatrix} \right)= Af \otimes \overline{A} \begin{pmatrix} \alpha \\ \beta \end{pmatrix}= Af \otimes \two{}{-i}{-i}{} \begin{pmatrix} \alpha \\ \beta \end{pmatrix} = Af \otimes \begin{pmatrix} -i \beta \\ -i\alpha \end{pmatrix}.
	\]
So in terms of the identification of $S \otimes_k \rho^* \cong S^2$,
	\[
	A \begin{pmatrix} f \\ g \end{pmatrix}= \begin{pmatrix} -iAg \\ -iAf \end{pmatrix}.
	\]
Similarly, 
	\[
	B \begin{pmatrix} f \\ g \end{pmatrix}= \begin{pmatrix} -iBf \\ iBg \end{pmatrix}.
	\]
So we want $f,g \in S$ such that $\begin{pmatrix} -iAg \\ -iAf \end{pmatrix}= \begin{pmatrix} f \\ g \end{pmatrix}= \begin{pmatrix} -iBf \\ iBg \end{pmatrix}$. Equivalently,
	\[
	\begin{pmatrix} -ig(iv,iu) \\ if(iv,iu) \end{pmatrix}= \begin{pmatrix} f(u,v) \\ g(u,v) \end{pmatrix}= \begin{pmatrix} -if(iu,-iv) \\ ig(iu,-iv) \end{pmatrix}.
	\] % *
We know there is at least one such pair of degree one from the Molien series. Consider $\begin{pmatrix} au+bv \\ cu+dv \end{pmatrix}$. Setting the above equation equal to this and comparing coefficients gives $b=c=0$ and $a=d$. This shows that $\begin{pmatrix} u \\ v \end{pmatrix} \in R_\rho$. Notice $\begin{pmatrix} v \\ u \end{pmatrix} \notin (S \otimes \rho^*)^G$! Instead, $\begin{pmatrix} v \\ u \end{pmatrix}$ lives in the other copy. Repeating with generic cubics $\begin{pmatrix} au^3+\cdots+dv^3 \\ eu^3+\cdots+uv^3 \end{pmatrix}$ to get two linearly independent cubics, namely $\begin{pmatrix} u^2v \\ -uv^2 \end{pmatrix}$ and $\begin{pmatrix} v^3 \\ u^3 \end{pmatrix}$. There are supposed to be 3 elements in degree 5
	\[
	\begin{split}
	u^2v^2 \begin{pmatrix} u \\ v \end{pmatrix}&= \begin{pmatrix} u^3v^2 \\ u^2v^3 \end{pmatrix} \\
	(u^4+v^4) \begin{pmatrix} u \\ v \end{pmatrix}= \begin{pmatrix} u^5+uv^4 \\ u^4v+v^5 \end{pmatrix}= \begin{pmatrix} u^5 \\ v^5 \end{pmatrix} + \begin{pmatrix} uv^4 \\ u^4v \end{pmatrix}
	\end{split}
	\]
and both $\begin{pmatrix} u^5 \\ v^5 \end{pmatrix}$ and $\begin{pmatrix} uv^4 \\ u^4v \end{pmatrix}$ are in $(S \otimes \rho^*)^G$. % By *

So we have thus far
	\[
	R \begin{pmatrix} u \\ v \end{pmatrix} + R \begin{pmatrix} u^2v \\ -uv^2 \end{pmatrix} + R \begin{pmatrix}  v^3 \\ u^3 \end{pmatrix} + R \begin{pmatrix} uv^4 \\ u^4v \end{pmatrix}
	\]
One then checks that multiplying these by elements of $R$ gives 4 linearly independent objects in degree 7. By Noether's bound, we are done, as previously mentioned. It is not hard to compute the relations among these generators, e.g. $Za_1= Xa_3 - 2Y a_2$. Then one can show 
	\[
	(S \otimes \rho^*)^G \cong \text{coker } 
	\begin{pmatrix}
	z & 0 & 2y^2 & -xy \\
	0 & -z & -x & 2y \\
	2y & -xy & -z & 0 \\
	-x & 2y^2 & 0 & z
	\end{pmatrix}
	\] \xqed
\end{ex}


\begin{rem}
If $G$ is abelian, all irreducible representations of $G$ are 1-dimensional. Then we can compute the isotypic components as semi-invariants
	\[
	R_\chi= \{ f \in S \colon g\cdot f= \chi(g) f \;\forall g \}.
	\]
Therefore in order to obtain something `interesting', one has to take $G$ non-abelian. 
\end{rem}


Recall that the \mc quiver of $G \subseteq \GL(V)$, has
	\begin{itemize}
	\item vertices $V_0,\ldots,V_d$ the irreducible representations of $G$
	\item $m_{ij}$ arrows $V_i \to V_j$ if $V_i$ appears with multiplicity $m_{ij}$ in $V \otimes V_j$
	\end{itemize}


\begin{dfn}[Gabriel/Auslander Quiver]
The Gabriel quiver of $G \subseteq \GL(V)$ has 
	\begin{itemize}
	\item vertices $P_0,\ldots,P_d$ the indecomposable projective $S\#G$-modules
	\item arrows as follows: take a minimal $S\#G$-projective resolution of $V_j= P_j/(\underline{x})P_j$
		\[
		0 \ma{} Q_{j,n} \ma{} \cdots \ma{} Q_{j,2} \ma{} Q_{j,1} \ma{} P_j \ma{} V_j \ma{} 0
		\]
	Decompose $Q_{j,1}$ into indecomposable projective $S\#G$-modules. Draw $m_{ij}$ arrows $P_i \to P_j$ if $P_i$ appears with multiplicity $m_{ij}$ in $Q_{j,1}$. 
	\end{itemize}
\end{dfn}


We know that $P_i \cong S \otimes_k V_i$ and $V_i = P_i/(\underline{x}) P_i$. We know also that $P_j= Q_{j,0}$ and that the resolution is finite since the global dimension of $S\#G$ is the same as the global dimension of $S$, which is $n$. 


\begin{thm}[Auslander]
The \mc quiver and the Gabriel quiver are isomorphic. 
\end{thm}

\pf First, we compute the projective resolution of the trivial representation $V_0= k$. The $P_0= S \otimes_k V_0= S \otimes_k k= S$. The $S\#G$-resolution of $V_0$ is just the Koszul complex:
	\[
	0 \ma{} \extp^n S^n \ma{} \cdots \ma{} \extp^2S^n \ma{} \extp^1 S^n \ma{} S \ma{} k \ma{} 0.
	\]
But we also have a resolution
	\[
	0 \ma{} S \otimes \extp^n V \ma{} S \otimes \extp^{n-1} V \ma{} \cdots \ma{} S \otimes \extp^1V \ma{} S \otimes \extp^0 V \ma{} k \ma{} 0,
	\]
where all the maps are $G$-linear. In particular, $Q_{0,1}= S \otimes \extp^1V= S \otimes V$. To resolve the other irreducibles $V_j$, tensor the Koszul complex with $V_j$. Since $- \otimes_k V_j$ is exact, we obtain a $S\#G$-projective resolution of $k \otimes_k V_j= V_j$,
	\[
	0 \ma{} S \otimes \extp^nV \otimes V_j \ma{} S \otimes \extp^{n-1}V \otimes V_j \ma{} \cdots \ma{} S \otimes \extp^2V \otimes V_j \ma{} S \otimes \extp^1V \otimes V_j \ma{} S \otimes \extp^0V \otimes V_j \ma{} V_j \ma{} 0.
	\]
So $Q_{j,1}= S \otimes \extp^1V \otimes V_j = S \otimes (V \otimes V_j)$.


\begin{ex}
Let $G= C_2$ act on $k[x,y,z]$ by letting the generator negate each variable. Note that then $R= k[x^2,xy,xz,y^2,yz,z^2]$. We compute the Gabriel quiver. There are only two irreducible representations: the trivial representation, call this $V_0$, and the representation which sends the generator to $-1$, call this $V_1$. The given representation, $V$, of $G$ sends the generator to $\three{-1}{}{}{}{-1}{}{}{}{-1}$. So $V= V_1 \oplus V_1 \oplus V_1= V_1^3$. We will need the Koszul complex, so we need to compute $\extp^kV$. Recall two facts about exterior powers over a field:
	\begin{itemize}
	\item $\extp^kA= 0$ for $k> \dim_k A$
	\item $\extp^k (A \oplus B)= \bigoplus_{i+j=k} (\extp^i A \otimes \extp^jB)$
	\end{itemize}
Since $\dim V= 3$, we only need $\extp^0V= k$, $\extp^1V= V$, and $\extp^2V= \extp^2( V_1 \oplus V_1 \oplus V_1)= (V_1 \otimes V_1) \oplus (V_1 \otimes V_1) \oplus (V_1 \otimes V_1)= (V_1 \otimes V_1)^3=(\text{triv})^3= V_0^3$, and $\extp^3V= \extp^3(V_1 \oplus V_1 \oplus V_1)= V_1 \otimes V_1 \otimes V_1 \cong V_1$. The Koszul complex is then 
	\[
	0  \ma{} S \otimes \extp^3V \ma{} S \otimes \extp^2V \ma{} S \otimes \extp^1V \ma{} S \otimes \extp^0V \ma{} 0.
	\]
This is the same as
	\[
	0 \ma{} S \otimes V_1 \ma{} S \otimes (V_0)^3 \ma{} S \otimes (V_1)^3 \ma{} S \otimes V_0 \ma{} 0
	\]
Here $Q_{0,1}= S \otimes V_1^3$, so we obtain three arrows 

% P_1 triple right arrow P_0

in the Gabriel quiver. Tensoring with $V_1$, 
	\[
	0 \ma{} S \otimes V_0 \ma{} S \otimes (V_1)^3 \ma{} S \otimes (V_0)^3 \ma{} S \otimes V_1 \ma{} 0
	\]
So the Gabriel quiver is 

% P_0 three curved arrows up top going from P_0 to P_1, and same below with three arrows going right to left from P_1 to P_0. Note, this was done earlier. 
\end{ex}

We now have the \mc quiver for representations and the Gabriel quiver for the $S\#G$-projectives. But we have many bijections from earlier work so there should be an object for indecomposable $R$-summands of $S$. This will turn out to be the $G$-invariants of the Gabriel quiver. 






























